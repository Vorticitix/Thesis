{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "#set path for my_tools script\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from cmap import ncl_colormap\n",
    "from my_tools import file_dic, plot_dic\n",
    "import matplotlib.ticker as plticker\n",
    "from mpl_toolkits.basemap import Basemap, addcyclic\n",
    "import string\n",
    "from matplotlib.patches import Polygon\n",
    "from scipy.stats import ttest_ind\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/onno/Volume/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_env = 'era51_mars_env_wledit2000-10000_latavg_v300_79-19_6hourly_smoothed.nc'\n",
    "file_cp = 'era51_mars_phasevel_wledit2000-10000_latavg_v300_envgt15_79-19_6hourly_setvrange_-100to100.nc'\n",
    "file_t850 = 'era51_mars_t850_79-19_6hourly_anom_from_smoothed04_clim.nc'\n",
    "file_v300 = 'era51_mars_v300_wledit2000-10000_latavg_79-19_6hourly.nc'\n",
    "file_z500 = 'era51_mars_phi500_79-19_6hourly.nc'\n",
    "file_mslp = 'era5_mslp_79-19_6hourly_remapbil2x2.nc'\n",
    "file_prec = 'era5_totprecip_79-19_1hourly_remapbil2x2_daysum.nc'\n",
    "file_z500_anom = 'era51_mars_phi500_79-19_6hourly_anom_from_smoothed04_clim_daymean.nc'\n",
    "file_z500_fcst = 'era5rf_z500_0-240h_12hourly_2x2nh_jan79-dec19.nc'\n",
    "\n",
    "\n",
    "# era_env = xr.open_dataset(path+file_env)\n",
    "# era_cp = xr.open_dataset(path+file_cp)\n",
    "# era_v300 = xr.open_dataset(path+file_v300)\n",
    "era_z500 = xr.open_dataset(path+file_z500)\n",
    "era_mslp = xr.open_dataset(path+file_mslp)\n",
    "# era_t850 = xr.open_dataset(path+file_t850)\n",
    "# era_prec = xr.open_dataset(path+file_prec)\n",
    "era_z500_anom = xr.open_dataset(path+file_z500_anom)\n",
    "era5rf_z500 = xr.open_dataset(path+file_z500_fcst,decode_times=False)\n",
    "# era_prec['time'] = [era_prec['time'].values[i] - pd.Timedelta(15,'h') if i==0 else \n",
    "#                    era_prec['time'].values[i] - pd.Timedelta(11.5,'h')\n",
    "#                     for i in range(len( era_prec['time'].values))]\n",
    "# era_prec = era_prec.drop('time_bnds')\n",
    "era_z500_anom['time'] = [era_z500_anom['time'].values[i] - pd.Timedelta(9,'h')\n",
    "                    for i in range(len(era_z500_anom['time'].values))]\n",
    "era_z500_anom = era_z500_anom.drop('time_bnds')\n",
    "ERA5RF_init_time = pd.Timestamp('1900-01-01')\n",
    "era5rf_z500['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in era5rf_z500.time.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eraz = {\n",
    "# #         'v300':era_v300,\n",
    "       'z500':era_z500,\n",
    "       'mslp':era_mslp,\n",
    "# #        't850':era_t850,\n",
    "#        'prec':era_prec,\n",
    "# #        'env':era_env,\n",
    "# #        'cp':era_cp,\n",
    "        'z500_anom':era_z500_anom\n",
    "}\n",
    "\n",
    "seasonz = ['DJF','MAM','JJA','SON']\n",
    "modelz = ['ERA5RF']\n",
    "# eventz = ['persistent_hw','persistent_cw']\n",
    "\n",
    "countryz={\n",
    "'Finland':{'warm':'/GFS_T850/dates/pw_lon_22_30_lat_68_60.npy',\n",
    "          'cold':'/GFS_T850/dates/pc_lon_22_30_lat_68_60.npy'},\n",
    "# 'Germany':{'warm':'/GFS_T850/dates/pw_lon_8_16_lat_54_46.npy',\n",
    "#           'cold':'/GFS_T850/dates/pc_lon_8_16_lat_54_46.npy'},\n",
    "# 'Spain':{'warm':'/GFS_T850/dates/pw_lon_352_360_lat_44_36.npy',\n",
    "#           'cold':'/GFS_T850/dates/pc_lon_352_360_lat_44_36.npy'},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for country in countryz:\n",
    "    for model in modelz:\n",
    "        for season in seasonz:\n",
    "            for key in eraz:\n",
    "                if 'lat' in list(eraz[key].dims):\n",
    "                    eraz[key]=eraz[key].rename({'lat':'latitude','lon':'longitude'})\n",
    "                file_cold = countryz[country]['cold']\n",
    "                file_warm = countryz[country]['warm']\n",
    "                warmz = np.load(path+file_warm,allow_pickle=True)\n",
    "                coldz = np.load(path+file_cold,allow_pickle=True)\n",
    "                datez_warmz = pd.to_datetime(pd.Series(warmz[:,0]))\n",
    "                datez_coldz = pd.to_datetime(pd.Series(coldz[:,0]))\n",
    "                if season == 'JJA':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=6)&(datez_warmz.dt.month<=8)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=6)&(datez_coldz.dt.month<=8)).dropna()\n",
    "                if season == 'DJF':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=12)|(datez_warmz.dt.month<=2)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=12)|(datez_coldz.dt.month<=2)).dropna()\n",
    "                if season == 'MAM':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=3)&(datez_warmz.dt.month<=5)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=3)&(datez_coldz.dt.month<=5)).dropna()\n",
    "                if season == 'SON':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=9)&(datez_warmz.dt.month<=11)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=9)&(datez_coldz.dt.month<=11)).dropna()\n",
    "                warm_compositez = []\n",
    "                cold_compositez = []\n",
    "                for date in datez_warmz:\n",
    "                    date = pd.Timestamp(date)\n",
    "                    if date < pd.Timestamp('1979-01-01')+pd.Timedelta(7,'days'):\n",
    "                        continue\n",
    "                    if date > pd.Timestamp('2019-12-31')-pd.Timedelta(10,'days'):\n",
    "                        continue\n",
    "                    begin_date = date - pd.Timedelta(7*24,'hours')\n",
    "                    end_date = date + pd.Timedelta(10*24,'hours')\n",
    "                    date_range = pd.date_range(begin_date,end_date,freq=\"24h\")\n",
    "                    era_select = eraz[key].sel(time=date_range)\n",
    "                    era_select['time'] = np.arange(-7,11)\n",
    "                    warm_compositez.append(era_select)\n",
    "                warm_composite_all = xr.concat(warm_compositez,'time').squeeze()\n",
    "                warm_composite = warm_composite_all.groupby('time').mean()\n",
    "                warm_composite_all_4D = my_tools.dataset_3D_to_4D(warm_composite_all)\n",
    "                warm_composite.to_netcdf(path+'/fcst_composite/reanalysis/composite_{}_warm_forecasts_{}_{}_{}.nc'.format(key,season,country,model))\n",
    "                for date in datez_coldz:\n",
    "                    date = pd.Timestamp(date)\n",
    "                    if date < pd.Timestamp('1979-01-01')+pd.Timedelta(7,'days'):\n",
    "                        continue\n",
    "                    if date > pd.Timestamp('2019-12-31')-pd.Timedelta(10,'days'):\n",
    "                        continue\n",
    "                    begin_date = date - pd.Timedelta(7*24,'hours')\n",
    "                    end_date = date + pd.Timedelta(10*24,'hours')\n",
    "                    date_range = pd.date_range(begin_date,end_date,freq=\"24h\")\n",
    "                    era_select = eraz[key].sel(time=date_range)\n",
    "                    era_select['time'] = np.arange(-7,11)\n",
    "                    cold_compositez.append(era_select)\n",
    "                cold_composite_all = xr.concat(cold_compositez,'time').squeeze()\n",
    "                cold_composite = cold_composite_all.groupby('time').mean()\n",
    "                cold_composite_all_4D = my_tools.dataset_3D_to_4D(cold_composite_all)\n",
    "                cold_composite.to_netcdf(path+'/fcst_composite/reanalysis/composite_{}_cold_forecasts_{}_{}_{}.nc'.format(key,season,country,model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eraz = {\n",
    "        'z500':era_z500\n",
    "}\n",
    "\n",
    "seasonz = ['DJF','MAM','JJA','SON']\n",
    "modelz = ['ERA5RF']\n",
    "# eventz = ['persistent_hw','persistent_cw']\n",
    "\n",
    "countryz={\n",
    "'Finland':{'warm':'/GFS_T850/dates/pw_lon_22_30_lat_68_60.npy',\n",
    "          'cold':'/GFS_T850/dates/pc_lon_22_30_lat_68_60.npy'},\n",
    "# 'Germany':{'warm':'/GFS_T850/dates/pw_lon_8_16_lat_54_46.npy',\n",
    "#           'cold':'/GFS_T850/dates/cw_lon_8_16_lat_54_46.npy'},\n",
    "# 'Spain':{'warm':'/GFS_T850/dates/pw_lon_352_360_lat_44_36.npy',\n",
    "#           'cold':'/GFS_T850/dates/cw_lon_352_360_lat_44_36.npy'},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for country in countryz:\n",
    "    for model in modelz:\n",
    "        for season in seasonz:\n",
    "            for key in eraz:\n",
    "                if 'lat' in list(eraz[key].dims):\n",
    "                    eraz[key]=eraz[key].rename({'lat':'latitude','lon':'longitude'})\n",
    "                file_cold = countryz[country]['cold']\n",
    "                file_warm = countryz[country]['warm']\n",
    "                warmz = np.load(path+file_warm,allow_pickle=True)\n",
    "                coldz = np.load(path+file_cold,allow_pickle=True)\n",
    "                datez_warmz = pd.to_datetime(pd.Series(warmz[:,0]))\n",
    "                datez_coldz = pd.to_datetime(pd.Series(coldz[:,0]))\n",
    "                if season == 'JJA':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=6)&(datez_warmz.dt.month<=8)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=6)&(datez_coldz.dt.month<=8)).dropna()\n",
    "                if season == 'DJF':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=12)|(datez_warmz.dt.month<=2)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=12)|(datez_coldz.dt.month<=2)).dropna()\n",
    "                if season == 'MAM':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=3)&(datez_warmz.dt.month<=5)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=3)&(datez_coldz.dt.month<=5)).dropna()\n",
    "                if season == 'SON':\n",
    "                    datez_warmz = datez_warmz.where((datez_warmz.dt.month>=9)&(datez_warmz.dt.month<=11)).dropna()\n",
    "                    datez_coldz = datez_coldz.where((datez_coldz.dt.month>=9)&(datez_coldz.dt.month<=11)).dropna()\n",
    "                warm_compositez = []\n",
    "                cold_compositez = []\n",
    "                for date in datez_warmz:\n",
    "                    date = pd.Timestamp(date)\n",
    "                    if date < pd.Timestamp('1979-01-01')+pd.Timedelta(5,'days'):\n",
    "                        continue\n",
    "                    if date > pd.Timestamp('2019-12-31')-pd.Timedelta(5,'days'):\n",
    "                        continue\n",
    "                    begin_date = date - pd.Timedelta(5*24,'hours')\n",
    "                    end_date = date + pd.Timedelta(5*24,'hours')\n",
    "                    date_range = pd.date_range(begin_date,end_date,freq=\"24h\")\n",
    "                    era_select = eraz[key].sel(time=date_range,latitude=slice(90,0))\n",
    "                    era5rf_select = era5rf_z500.sel(time=begin_date,lead=np.linspace(0,240,11))\n",
    "                    era_select['time'] = np.arange(-5,6)\n",
    "                    diff = era5rf_select.Z.values - era_select.z/(9.80665*10)\n",
    "                    warm_compositez.append(diff)\n",
    "                warm_composite_all = xr.concat(warm_compositez,'time').squeeze().to_dataset()\n",
    "                warm_composite = warm_composite_all.groupby('time').mean()\n",
    "                warm_composite_all_4D = my_tools.dataset_3D_to_4D(warm_composite_all,N_days=11)\n",
    "                warm_composite.to_netcdf(path+'/fcst_composite/reanalysis/diff_{}_warm_forecasts_{}_{}_{}.nc'.format(key,season,country,model))\n",
    "                for date in datez_coldz:\n",
    "                    date = pd.Timestamp(date)\n",
    "                    if date < pd.Timestamp('1979-01-01')+pd.Timedelta(5,'days'):\n",
    "                        continue\n",
    "                    if date > pd.Timestamp('2019-12-31')-pd.Timedelta(5,'days'):\n",
    "                        continue\n",
    "                    begin_date = date - pd.Timedelta(5*24,'hours')\n",
    "                    end_date = date + pd.Timedelta(5*24,'hours')\n",
    "                    date_range = pd.date_range(begin_date,end_date,freq=\"24h\")\n",
    "                    era_select = eraz[key].sel(time=date_range,latitude=slice(90,0))\n",
    "                    era5rf_select = era5rf_z500.sel(time=begin_date,lead=np.linspace(0,240,11))\n",
    "                    era_select['time'] = np.arange(-5,6)\n",
    "                    diff = era5rf_select.Z.values - era_select.z/(9.80665*10)\n",
    "                    cold_compositez.append(diff)\n",
    "                cold_composite_all = xr.concat(cold_compositez,'time').squeeze().to_dataset()\n",
    "                cold_composite = cold_composite_all.groupby('time').mean()\n",
    "                cold_composite_all_4D = my_tools.dataset_3D_to_4D(cold_composite_all,N_days=11)\n",
    "                cold_composite.to_netcdf(path+'/fcst_composite/reanalysis/diff_{}_cold_forecasts_{}_{}_{}.nc'.format(key,season,country,model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "composite MSLP and Z500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['hatch.color'] = 'w'\n",
    "seasonz = ['DJF','MAM','JJA','SON']\n",
    "modelz = ['ERA5RF']\n",
    "eventz = ['persistent_hw','persistent_cw']\n",
    "event_labelz = ['Warm Extreme','Cold Extreme']\n",
    "regionz = ['Germany']\n",
    "file_warm_mslp = '/fcst_composite/reanalysis/composite_mslp_warm_forecasts_{}_{}_{}.nc'\n",
    "file_cold_mslp = '/fcst_composite/reanalysis/composite_mslp_cold_forecasts_{}_{}_{}.nc'\n",
    "# file_p_mslp = '/fcst_composite/reanalysis/composite_mslp_diff_p_value_{}_{}_{}_{}.nc'\n",
    "file_warm_z500 = '/fcst_composite/reanalysis/composite_z500_warm_forecasts_{}_{}_{}.nc'\n",
    "file_cold_z500 = '/fcst_composite/reanalysis/composite_z500_cold_forecasts_{}_{}_{}.nc'\n",
    "# file_p_z500 = '/fcst_composite/reanalysis/composite_z500_diff_p_value_{}_{}_{}_{}.nc'\n",
    "file_diff_warm_z500 = '/fcst_composite/reanalysis/diff_z500_warm_forecasts_{}_{}_{}.nc'\n",
    "file_diff_cold_z500 = '/fcst_composite/reanalysis/diff_z500_cold_forecasts_{}_{}_{}.nc'\n",
    "\n",
    "for region in regionz:\n",
    "    for model in modelz:\n",
    "        for season in seasonz:\n",
    "            fig,axz = plt.subplots(5,2,figsize=(18,10))\n",
    "            ds_warm_z500 = xr.open_dataset(path+file_warm_z500.format(season,region,model))\n",
    "            ds_cold_z500 = xr.open_dataset(path+file_cold_z500.format(season,region,model))     \n",
    "            ds_diff_warm_z500 = xr.open_dataset(path+file_diff_warm_z500.format(season,region,model)).sel(latitude=slice(85,0))\n",
    "            ds_diff_cold_z500 = xr.open_dataset(path+file_diff_cold_z500.format(season,region,model)).sel(latitude=slice(85,0))               \n",
    "            ds_warm_mslp = xr.open_dataset(path+file_warm_mslp.format(season,region,model))\n",
    "            ds_cold_mslp = xr.open_dataset(path+file_cold_mslp.format(season,region,model))      \n",
    "            days_to_plot = np.arange(-4,5,2)\n",
    "            for i in range(len(days_to_plot)):\n",
    "                ds_warm_z500_day = ds_warm_z500.sel(time=days_to_plot[i])\n",
    "                ds_warm_z500_day_cyclic, lon_cyclic = addcyclic(ds_warm_z500_day.z.values, ds_warm_z500_day.longitude.values)\n",
    "                ds_diff_warm_z500_day = ds_diff_warm_z500.sel(time=days_to_plot[i])\n",
    "                ds_diff_warm_z500_day_cyclic, lon_cyclic_diff = addcyclic(ds_diff_warm_z500_day.z.values, ds_diff_warm_z500_day.longitude.values)                \n",
    "\n",
    "                ds_warm_mslp_day = ds_warm_mslp.sel(time=days_to_plot[i])\n",
    "                ds_warm_mslp_day_cyclic, lon_cyclic = addcyclic(ds_warm_mslp_day.var151.values, ds_warm_mslp_day.longitude.values)\n",
    "\n",
    "                lon,lat = np.meshgrid(lon_cyclic,ds_warm_z500_day.latitude.values)\n",
    "                lon_diff,lat_diff = np.meshgrid(lon_cyclic_diff,ds_diff_warm_z500_day.latitude.values)\n",
    "\n",
    "                ax_warm = axz[i,0]\n",
    "                ax_warm.set_title('Warm Extremes Day {}'.format(days_to_plot[i]))\n",
    "                m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_warm,\n",
    "                            llcrnrlon=-180,llcrnrlat=15,urcrnrlon=180,urcrnrlat=75)\n",
    "                m.drawcoastlines()\n",
    "                m.contourf(lon,lat,ds_warm_z500_day_cyclic/(9.80665*10),latlon='true',\n",
    "                          vmin=450,vmax=600,cmap=ncl_colormap(),levels=np.linspace(450,600,30),extend='both')\n",
    "                m.contour(lon,lat,ds_warm_mslp_day_cyclic/100,latlon='true',\n",
    "                          vmin=970,vmax=1040,levels=np.arange(970,1041,5),cmap='Greys',linewidths=.75)\n",
    "                m.contour(lon_diff,lat_diff,ds_diff_warm_z500_day_cyclic,latlon='true',\n",
    "                          vmin=-6,vmax=6,levels=[-6,-4,-2,2,4,6],cmap='bwr',extend='both')\n",
    "\n",
    "                ds_cold_z500_day = ds_cold_z500.sel(time=days_to_plot[i])\n",
    "                ds_cold_z500_day_cyclic, lon_cyclic = addcyclic(ds_cold_z500_day.z.values, ds_cold_z500_day.longitude.values)\n",
    "                ds_diff_cold_z500_day = ds_diff_cold_z500.sel(time=days_to_plot[i])\n",
    "                ds_diff_cold_z500_day_cyclic, lon_cyclic = addcyclic(ds_diff_cold_z500_day.z.values, ds_diff_cold_z500_day.longitude.values)                \n",
    "\n",
    "                ds_cold_mslp_day = ds_cold_mslp.sel(time=days_to_plot[i])\n",
    "                ds_cold_mslp_day_cyclic, lon_cyclic = addcyclic(ds_cold_mslp_day.var151.values, ds_cold_mslp_day.longitude.values)\n",
    "\n",
    "                lon,lat = np.meshgrid(lon_cyclic,ds_cold_z500_day.latitude.values)\n",
    "                lon_diff,lat_diff = np.meshgrid(lon_cyclic_diff,ds_diff_cold_z500_day.latitude.values)\n",
    "\n",
    "                ax_cold = axz[i,1]\n",
    "                ax_cold.set_title('Cold Extremes Day {}'.format(days_to_plot[i]))\n",
    "\n",
    "                m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_cold,\n",
    "                            llcrnrlon=-180,llcrnrlat=15,urcrnrlon=180,urcrnrlat=75)\n",
    "                m.drawcoastlines()\n",
    "                im = m.contourf(lon,lat,ds_cold_z500_day_cyclic/(9.80665*10),latlon='true',\n",
    "                          vmin=450,vmax=600,cmap=ncl_colormap(),levels=np.linspace(450,600,30),extend='both')\n",
    "                m.contour(lon,lat,ds_cold_mslp_day_cyclic/100,latlon='true',\n",
    "                          vmin=970,vmax=1040,levels=np.arange(970,1041,5),cmap='Greys',linewidths=.75)\n",
    "                m.contour(lon_diff,lat_diff,ds_diff_cold_z500_day_cyclic,latlon='true',\n",
    "                          vmin=-6,vmax=6,levels=[-6,-4,-2,2,4,6],cmap='bwr',extend='both')\n",
    "\n",
    "\n",
    "\n",
    "            fig.subplots_adjust(left=0.025,right=0.975,top=0.95,bottom=0.105,wspace=0,hspace=0.1)     \n",
    "            fig.suptitle('Composites Z500 (contours), Z500 forecast error and MSLP (contour lines) {} {} {}'.format(season,region,model))\n",
    "\n",
    "            cbax = fig.add_axes([0.2,0.07,0.6,0.015])\n",
    "\n",
    "            cbar = fig.colorbar(im,cax=cbax,orientation='horizontal',ticks=np.arange(450,601,25))\n",
    "            cbar.ax.set_xlabel('Z 500 hPa [m]')\n",
    "            fig.savefig(path+'fcst_composite/reanalysis/figures/composite_z500_mslp_{}_{}_{}_error.png'.format(season,region,model))\n",
    "#                 fig.savefig(path+'fcst_composite/reanalysis/figures/try.png'.format(event,season,region,model))\n",
    "            plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "composite MSLP and Z500 anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['hatch.color'] = 'k'\n",
    "seasonz = ['DJF','MAM','JJA','SON']\n",
    "modelz = ['ERA5RF']\n",
    "eventz = ['persistent_hw','persistent_cw']\n",
    "regionz = ['Germany']\n",
    "event_labelz = ['Warm Extreme','Cold Extreme']\n",
    "file_warm_z500 = '/fcst_composite/reanalysis/composite_z500_warm_forecasts_{}_{}_{}.nc'\n",
    "file_cold_z500 = '/fcst_composite/reanalysis/composite_z500_cold_forecasts_{}_{}_{}.nc'\n",
    "file_warm_z500_anom = '/fcst_composite/reanalysis/composite_z500_anom_warm_forecasts_{}_{}_{}.nc'\n",
    "file_cold_z500_anom = '/fcst_composite/reanalysis/composite_z500_anom_cold_forecasts_{}_{}_{}.nc'\n",
    "file_diff_warm_z500 = '/fcst_composite/reanalysis/diff_z500_warm_forecasts_{}_{}_{}.nc'\n",
    "file_diff_cold_z500 = '/fcst_composite/reanalysis/diff_z500_cold_forecasts_{}_{}_{}.nc'\n",
    "\n",
    "for region in regionz:\n",
    "    for model in modelz:\n",
    "        for season in seasonz:\n",
    "            fig,axz = plt.subplots(5,2,figsize=(18,10))\n",
    "            ds_warm_z500 = xr.open_dataset(path+file_warm_z500.format(season,region,model))\n",
    "            ds_cold_z500 = xr.open_dataset(path+file_cold_z500.format(season,region,model))\n",
    "            ds_diff_warm_z500 = xr.open_dataset(path+file_diff_warm_z500.format(season,region,model)).sel(latitude=slice(85,0))\n",
    "            ds_diff_cold_z500 = xr.open_dataset(path+file_diff_cold_z500.format(season,region,model)).sel(latitude=slice(85,0))  \n",
    "            ds_warm_z500_anom = xr.open_dataset(path+file_warm_z500_anom.format(season,region,model))\n",
    "            ds_cold_z500_anom = xr.open_dataset(path+file_cold_z500_anom.format(season,region,model))      \n",
    "            days_to_plot = np.arange(-4,5,2)\n",
    "            for i in range(len(days_to_plot)):\n",
    "                ds_warm_z500_day = ds_warm_z500.sel(time=days_to_plot[i])\n",
    "                ds_warm_z500_day_cyclic, lon_cyclic = addcyclic(ds_warm_z500_day.z.values, ds_warm_z500_day.longitude.values)\n",
    "                ds_diff_warm_z500_day = ds_diff_warm_z500.sel(time=days_to_plot[i])\n",
    "                ds_diff_warm_z500_day_cyclic, lon_cyclic_diff = addcyclic(ds_diff_warm_z500_day.z.values, ds_diff_warm_z500_day.longitude.values)                \n",
    "                ds_warm_z500_anom_day = ds_warm_z500_anom.sel(time=days_to_plot[i])\n",
    "                ds_warm_z500_anom_day_cyclic, lon_cyclic = addcyclic(ds_warm_z500_anom_day.z.values, ds_warm_z500_anom_day.longitude.values)                \n",
    "                lon,lat = np.meshgrid(lon_cyclic,ds_warm_z500_day.latitude.values)\n",
    "                lon_diff,lat_diff = np.meshgrid(lon_cyclic_diff,ds_diff_warm_z500_day.latitude.values)\n",
    "\n",
    "\n",
    "                ax_warm = axz[i,0]\n",
    "                ax_warm.set_title('Warm Extremes Day {}'.format(days_to_plot[i]))\n",
    "                m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_warm,\n",
    "                            llcrnrlon=-180,llcrnrlat=15,urcrnrlon=180,urcrnrlat=75)\n",
    "                m.drawcoastlines()\n",
    "                m.contour(lon,lat,ds_warm_z500_day_cyclic/(9.80665*10),latlon='true',colors='k',\n",
    "                          vmin=450,vmax=600,levels=np.arange(450,601,10),linewidths=.5)\n",
    "                m.contourf(lon,lat,ds_warm_z500_anom_day_cyclic/(9.80665*10),latlon='true',\n",
    "                          vmin=-25,vmax=25,cmap='bwr',levels=np.linspace(-25,25,51),extend='both')\n",
    "                m.contour(lon_diff,lat_diff,ds_diff_warm_z500_day_cyclic,latlon='true',\n",
    "                          vmin=-6,vmax=6,levels=[-6,-4,-2,2,4,6],cmap='bwr',extend='both')\n",
    "\n",
    "                ds_cold_z500_day = ds_cold_z500.sel(time=days_to_plot[i])\n",
    "                ds_cold_z500_day_cyclic, lon_cyclic = addcyclic(ds_cold_z500_day.z.values, ds_cold_z500_day.longitude.values)\n",
    "                ds_diff_cold_z500_day = ds_diff_cold_z500.sel(time=days_to_plot[i])\n",
    "                ds_diff_cold_z500_day_cyclic, lon_cyclic_diff = addcyclic(ds_diff_cold_z500_day.z.values, ds_diff_cold_z500_day.longitude.values)                \n",
    "                ds_cold_z500_anom_day = ds_cold_z500_anom.sel(time=days_to_plot[i])\n",
    "                ds_cold_z500_anom_day_cyclic, lon_cyclic = addcyclic(ds_cold_z500_anom_day.z.values, ds_cold_z500_anom_day.longitude.values)\n",
    "                lon,lat = np.meshgrid(lon_cyclic,ds_cold_z500_day.latitude.values)\n",
    "                lon_diff,lat_diff = np.meshgrid(lon_cyclic_diff,ds_diff_cold_z500_day.latitude.values)\n",
    "\n",
    "\n",
    "                ax_cold = axz[i,1]\n",
    "                ax_cold.set_title('Cold Extremes Day {}'.format(days_to_plot[i]))\n",
    "\n",
    "                m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_cold,\n",
    "                            llcrnrlon=-180,llcrnrlat=15,urcrnrlon=180,urcrnrlat=75)\n",
    "                m.drawcoastlines()\n",
    "                m.contour(lon,lat,ds_cold_z500_day_cyclic/(9.80665*10),latlon='true',colors='k',\n",
    "                          vmin=450,vmax=600,levels=np.arange(-25,601,10),linewidths=.5)\n",
    "                im = m.contourf(lon,lat,ds_cold_z500_anom_day_cyclic/(9.80665*10),latlon='true',\n",
    "                          vmin=-25,vmax=25,cmap='bwr',levels=np.linspace(-25,25,51),extend='both')\n",
    "                m.contour(lon_diff,lat_diff,ds_diff_cold_z500_day_cyclic,latlon='true',\n",
    "                          vmin=-6,vmax=6,levels=[-6,-4,-2,2,4,6],cmap='bwr',extend='both')\n",
    "\n",
    "\n",
    "\n",
    "            fig.subplots_adjust(left=0.025,right=0.975,top=0.95,bottom=0.105,wspace=0,hspace=0.1)     \n",
    "            fig.suptitle('Z500 Anomaly (contours) and Z500 (contour lines) {} {} {}'.format(season,region,model))\n",
    "\n",
    "            cbax = fig.add_axes([0.2,0.07,0.6,0.015])\n",
    "\n",
    "            cbar = fig.colorbar(im,cax=cbax,orientation='horizontal',ticks=np.linspace(-25,25,11))\n",
    "            cbar.ax.set_xlabel('Z\\' 500 hPa [m]')\n",
    "            fig.savefig(path+'fcst_composite/reanalysis/figures/composite_z500_anom_z500_{}_{}_{}_error.png'.format(season,region,model))\n",
    "            plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composite Daily Precipiation Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['hatch.color'] = 'w'\n",
    "seasonz = ['DJF','MAM','JJA','SON','annual']\n",
    "modelz = ['GFS']\n",
    "eventz = ['persistent_hw','persistent_cw']\n",
    "event_labelz = ['Warm Extreme','Cold Extreme']\n",
    "file_good_prec = '/fcst_composite/reanalysis/composite_prec_good_forecasts_{}_{}_{}_{}.nc'\n",
    "file_bad_prec = '/fcst_composite/reanalysis/composite_prec_bad_forecasts_{}_{}_{}_{}.nc'\n",
    "file_p_prec = '/fcst_composite/reanalysis/composite_prec_diff_p_value_{}_{}_{}_{}.nc'\n",
    "clr_levels = [0,0.5,1,2,3,4,5,7.5,10,15,20]\n",
    "regionz = ['Germany','Finland','Spain']\n",
    "\n",
    "for region in regionz:\n",
    "    for model in modelz:\n",
    "        for j, event in enumerate(eventz):\n",
    "            for season in seasonz:\n",
    "                fig,axz = plt.subplots(6,2,figsize=(18,14))\n",
    "                ds_good_prec = xr.open_dataset(path+file_good_prec.format(event,season,region,model))\n",
    "                ds_bad_prec = xr.open_dataset(path+file_bad_prec.format(event,season,region,model))\n",
    "                days_to_plot = np.arange(-6,5,2)\n",
    "                for i in range(len(days_to_plot)):\n",
    "    #                 ds_p_prec_day = ds_p_prec.sel(days=days_to_plot[i])\n",
    "    #                 ds_p_prec_day_bool = ds_p_prec_day.p<0.05\n",
    "    #                 ds_p_prec_day_cyclic, lon_cyclic = addcyclic(ds_p_prec_day_bool.values, ds_p_prec_day.longitude.values)\n",
    "                    ds_good_prec_day = ds_good_prec.sel(time=days_to_plot[i])\n",
    "                    ds_good_prec_day_cyclic, lon_cyclic = addcyclic(ds_good_prec_day.tp.values, ds_good_prec_day.longitude.values)                \n",
    "                    lon,lat = np.meshgrid(lon_cyclic,ds_good_prec_day.latitude.values)\n",
    "\n",
    "                    ax_good = axz[i,0]\n",
    "                    ax_good.set_title('Good Forecasts Day {}'.format(days_to_plot[i]))\n",
    "                    m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_good,\n",
    "                                llcrnrlon=-180,llcrnrlat=-15,urcrnrlon=180,urcrnrlat=75)\n",
    "                    m.drawcoastlines()\n",
    "                    m.contourf(lon,lat,ds_good_prec_day_cyclic*1000,latlon='true',\n",
    "                              vmin=0,vmax=20,cmap='ocean_r',levels=clr_levels,extend='both')\n",
    "    #                 m.contourf(lon,lat,ds_p_prec_day_cyclic,3,latlon='true',\n",
    "    #                           colors='none',hatches=[None,'xx'])\n",
    "                    ds_bad_prec_day = ds_bad_prec.sel(time=days_to_plot[i])\n",
    "                    ds_bad_prec_day_cyclic, lon_cyclic = addcyclic(ds_bad_prec_day.tp.values, ds_bad_prec_day.longitude.values)\n",
    "                    lon,lat = np.meshgrid(lon_cyclic,ds_bad_prec_day.latitude.values)\n",
    "\n",
    "                    ax_bad = axz[i,1]\n",
    "                    ax_bad.set_title('Bad Forecasts Day {}'.format(days_to_plot[i]))\n",
    "\n",
    "                    m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_bad,\n",
    "                                llcrnrlon=-180,llcrnrlat=-15,urcrnrlon=180,urcrnrlat=75)\n",
    "                    m.drawcoastlines()\n",
    "                    im = m.contourf(lon,lat,ds_bad_prec_day_cyclic*1000,latlon='true',\n",
    "                              vmin=0,vmax=20,cmap='ocean_r',levels=clr_levels,extend='both')\n",
    "    #                 m.contourf(lon,lat,ds_p_prec_day_cyclic,3,latlon='true',\n",
    "    #                           colors='none',hatches=[None,'xx'])\n",
    "\n",
    "\n",
    "\n",
    "                fig.subplots_adjust(left=0.025,right=0.975,top=0.95,bottom=0.105,wspace=0,hspace=0.1)     \n",
    "                fig.suptitle('Daily Precipitation Sum {} {} {} {}'.format(season,event_labelz[j],region,model))\n",
    "\n",
    "                cbax = fig.add_axes([0.2,0.07,0.6,0.015])\n",
    "\n",
    "                cbar = fig.colorbar(im,cax=cbax,orientation='horizontal',ticks=clr_levels)\n",
    "                cbar.ax.set_xlabel('P_sum [mm]')\n",
    "                fig.savefig(path+'fcst_composite/reanalysis/figures/composite_prec_{}_{}_{}_{}.png'.format(event,season,region,model))\n",
    "                plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composite RWP Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['hatch.color'] = 'w'\n",
    "seasonz = ['annual']\n",
    "modelz = ['GFS','ERA5RF']\n",
    "eventz = ['persistent_hw','persistent_cw']\n",
    "event_labelz = ['Warm Extreme','Cold Extreme']\n",
    "file_good_env = '/fcst_composite/reanalysis/composite_env_good_forecasts_{}_{}_{}_{}.nc'\n",
    "file_bad_env = '/fcst_composite/reanalysis/composite_env_bad_forecasts_{}_{}_{}_{}.nc'\n",
    "file_p_env = '/fcst_composite/reanalysis/composite_env_diff_p_value_{}_{}_{}_{}.nc'\n",
    "\n",
    "for region in regionz:\n",
    "    for model in modelz:\n",
    "        for j, event in enumerate(eventz):\n",
    "            for season in seasonz:\n",
    "                fig,axz = plt.subplots(6,2,figsize=(18,12))\n",
    "                ds_good_env = xr.open_dataset(path+file_good_env.format(event,season,region,model))\n",
    "                ds_bad_env = xr.open_dataset(path+file_bad_env.format(event,season,region,model))\n",
    "                ds_p_env = xr.open_dataset(path+file_p_env.format(event,season,region,model))\n",
    "\n",
    "                days_to_plot = np.arange(-6,5,2)\n",
    "                for i in range(len(days_to_plot)):\n",
    "                    ds_p_env_day = ds_p_env.sel(days=days_to_plot[i])\n",
    "                    ds_p_env_day_bool = ds_p_env_day.p<0.05\n",
    "                    ds_p_env_day_cyclic, lon_cyclic = addcyclic(ds_p_env_day_bool.values, ds_p_env_day.longitude.values)\n",
    "                    ds_good_env_day = ds_good_env.sel(time=days_to_plot[i])\n",
    "                    ds_good_env_day_cyclic, lon_cyclic = addcyclic(ds_good_env_day.v.values, ds_good_env_day.longitude.values)                \n",
    "                    lon,lat = np.meshgrid(lon_cyclic,ds_good_env_day.latitude.values)\n",
    "\n",
    "                    ax_good = axz[i,0]\n",
    "                    ax_good.set_title('Good Forecasts Day {}'.format(days_to_plot[i]))\n",
    "                    m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_good,\n",
    "                                llcrnrlon=-180,llcrnrlat=15,urcrnrlon=180,urcrnrlat=75)\n",
    "                    m.drawcoastlines()\n",
    "                    m.contourf(lon,lat,ds_good_env_day_cyclic,latlon='true',\n",
    "                              vmin=0,vmax=50,cmap=ncl_colormap(),levels=np.linspace(0,50,26),extend='both')\n",
    "                    m.contourf(lon,lat,ds_p_env_day_cyclic,3,latlon='true',\n",
    "                              colors='none',hatches=[None,'xx'])\n",
    "\n",
    "                    ds_bad_env_day = ds_bad_env.sel(time=days_to_plot[i])\n",
    "                    ds_bad_env_day_cyclic, lon_cyclic = addcyclic(ds_bad_env_day.v.values, ds_bad_env_day.longitude.values)\n",
    "                    lon,lat = np.meshgrid(lon_cyclic,ds_bad_env_day.latitude.values)\n",
    "\n",
    "                    ax_bad = axz[i,1]\n",
    "                    ax_bad.set_title('Bad Forecasts Day {}'.format(days_to_plot[i]))\n",
    "\n",
    "                    m = Basemap(projection='cyl',lat_0=50,lon_0=0,resolution='c',ax=ax_bad,\n",
    "                                llcrnrlon=-180,llcrnrlat=15,urcrnrlon=180,urcrnrlat=75)\n",
    "                    m.drawcoastlines()\n",
    "                    im = m.contourf(lon,lat,ds_bad_env_day_cyclic,latlon='true',\n",
    "                              vmin=0,vmax=50,cmap=ncl_colormap(),levels=np.linspace(0,50,26),extend='both')\n",
    "                    m.contourf(lon,lat,ds_p_env_day_cyclic,3,latlon='true',\n",
    "                              colors='none',hatches=[None,'xx'])\n",
    "\n",
    "\n",
    "\n",
    "                fig.subplots_adjust(left=0.025,right=0.975,top=0.95,bottom=0.105,wspace=0,hspace=0.1)     \n",
    "                fig.suptitle('RWP Envelope {} {} {} {}'.format(season,event_labelz[j],region,model))\n",
    "\n",
    "                cbax = fig.add_axes([0.2,0.07,0.6,0.015])\n",
    "\n",
    "                cbar = fig.colorbar(im,cax=cbax,orientation='horizontal',ticks=np.arange(0,51,10))\n",
    "                cbar.ax.set_xlabel('E [/sm]')\n",
    "                fig.savefig(path+'fcst_composite/reanalysis/figures/composite_env_{}_{}_{}_{}.png'.format(event,season,region,model))\n",
    "                plt.close(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['hatch.color'] = 'k'\n",
    "seasonz = ['DJF','MAM','JJA','SON']\n",
    "modelz = ['GFS','ERA5RF']\n",
    "eventz = ['persistent_hw','persistent_cw']\n",
    "event_labelz = ['Warm Extreme','Cold Extreme']\n",
    "file_good_cp = '/fcst_composite/reanalysis/composite_cp_good_forecasts_{}_{}_{}_{}.nc'\n",
    "file_bad_cp = '/fcst_composite/reanalysis/composite_cp_bad_forecasts_{}_{}_{}_{}.nc'\n",
    "file_p_cp = '/fcst_composite/reanalysis/composite_cp_diff_p_value_{}_{}_{}_{}.nc'\n",
    "\n",
    "for model in modelz:\n",
    "    for j, event in enumerate(eventz):\n",
    "        for season in seasonz:\n",
    "            fig,axz = plt.subplots(3,4,figsize=(20,9))\n",
    "            ds_good_cp = xr.open_dataset(path+file_good_cp.format(event,season,region,model))\n",
    "            ds_bad_cp = xr.open_dataset(path+file_bad_cp.format(event,season,region,model))\n",
    "            ds_p_cp = xr.open_dataset(path+file_p_cp.format(event,season,region,model))\n",
    "\n",
    "            days_to_plot = np.arange(-6,5,2)\n",
    "            for i in range(len(days_to_plot)):\n",
    "                ds_p_cp_day = ds_p_cp.sel(days=days_to_plot[i])\n",
    "                ds_p_cp_day_bool = ds_p_cp_day.p<0.05\n",
    "                ds_p_cp_day_cyclic, lon_cyclic = addcyclic(ds_p_cp_day_bool.values, ds_p_cp_day.longitude.values)\n",
    "                ds_good_cp_day = ds_good_cp.sel(time=days_to_plot[i])\n",
    "                ds_good_cp_day_cyclic, lon_cyclic = addcyclic(ds_good_cp_day.v.values, ds_good_cp_day.longitude.values)                \n",
    "                lon,lat = np.meshgrid(lon_cyclic,ds_good_cp_day.latitude.values)\n",
    "                \n",
    "                ax_good = axz[i%3,(i//3)*2]\n",
    "                ax_good.set_title('Good Forecasts Day {}'.format(days_to_plot[i]))\n",
    "                m = Basemap(projection='merc',lat_0=50,lon_0=-40,resolution='c',ax=ax_good,\n",
    "                    llcrnrlon=-150,llcrnrlat=15,urcrnrlon=60,urcrnrlat=75)\n",
    "                m.drawcoastlines()\n",
    "                m.contourf(lon,lat,ds_good_cp_day_cyclic,latlon='true',alpha=.5,antialiased=True,\n",
    "                          vmin=-10,vmax=10,cmap='bwr',levels=np.linspace(-5,10,16),extend='both')\n",
    "                m.contourf(lon,lat,ds_p_cp_day_cyclic,3,latlon='true',\n",
    "                          colors='none',hatches=[None,'xx'])\n",
    "                \n",
    "                ds_bad_cp_day = ds_bad_cp.sel(time=days_to_plot[i])\n",
    "                ds_bad_cp_day_cyclic, lon_cyclic = addcyclic(ds_bad_cp_day.v.values, ds_bad_cp_day.longitude.values)\n",
    "                lon,lat = np.meshgrid(lon_cyclic,ds_bad_cp_day.latitude.values)\n",
    "                \n",
    "                ax_bad = axz[i%3,(i//3)*2+1]\n",
    "                ax_bad.set_title('Bad Forecasts Day {}'.format(days_to_plot[i]))\n",
    "\n",
    "                m = Basemap(projection='merc',lat_0=50,lon_0=-40,resolution='c',ax=ax_bad,\n",
    "                    llcrnrlon=-150,llcrnrlat=15,urcrnrlon=60,urcrnrlat=75)\n",
    "                m.drawcoastlines()\n",
    "                im = m.contourf(lon,lat,ds_bad_cp_day_cyclic,latlon='true',alpha=.5,antialiased=True,\n",
    "                          vmin=-10,vmax=10,cmap='bwr',levels=np.linspace(-5,10,16),extend='both')\n",
    "                m.contourf(lon,lat,ds_p_cp_day_cyclic,3,latlon='true',\n",
    "                          colors='none',hatches=[None,'xx'])\n",
    "                \n",
    "\n",
    "                \n",
    "            fig.subplots_adjust(left=0.025,right=0.975,top=0.95,bottom=0.105,wspace=0,hspace=0.1)     \n",
    "            fig.suptitle('RWP Phase Speed {} {} {}'.format(season,event_labelz[j],model))\n",
    "            \n",
    "            cbax = fig.add_axes([0.2,0.07,0.6,0.015])\n",
    "\n",
    "            cbar = fig.colorbar(im,cax=cbax,orientation='horizontal',ticks=np.linspace(-5,10,4))\n",
    "            cbar.ax.set_xlabel('Cp [m/s]')\n",
    "            fig.savefig(path+'fcst_composite/reanalysis/figures/composite_cp_{}_{}_{}_{}.png'.format(event,season,region,model))\n",
    "            plt.close(fig)\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
