{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from my_tools import plot_dic, file_dic\n",
    "%matplotlib qt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path\n",
    "path = '/media/onno/Volume/GFS_T850/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Mean Absolute Error for every single vent on lead days 1, 3, 5, 7 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-fda7be43baf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#set fcst time data to datetime object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0minit_time_fcst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1979-01-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mfcst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfcst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hours'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minit_time_fcst\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfcst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mfcst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#group forecast by lead time and take daily means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-fda7be43baf2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#set fcst time data to datetime object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0minit_time_fcst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1979-01-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mfcst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfcst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hours'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minit_time_fcst\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfcst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mfcst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#group forecast by lead time and take daily means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attr_sources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         raise AttributeError(\n\u001b[1;32m    229\u001b[0m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/core/coordinates.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataArray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataArray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coord_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataArray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lonz_0 = np.arange(-148,56.1,4,dtype=np.int64)\n",
    "lonz_1 = np.arange(-144,60.1,4,dtype=np.int64)\n",
    "latz_0 = np.arange(30,74.1,4,dtype=np.int64)\n",
    "latz_1 = np.arange(34,78.1,4,dtype=np.int64)\n",
    "lonz_0 = [int(i+360) if i<0 else int(i) for i in lonz_0]\n",
    "lonz_1 = [int(i+360) if i<=0 else int(i) for i in lonz_1]\n",
    "\n",
    "seasonz = {'MAM':[3,4,5],\n",
    "          'JJA':[6,7,8],\n",
    "          'SON':[9,10,11],\n",
    "          'DJF':[12,1,2]}\n",
    "\n",
    "\n",
    "count=0\n",
    "#Choose Forecast model: GFS or ERA5RF\n",
    "fcst_modelz = ['ERA5RF']\n",
    "for fcst_model in fcst_modelz:\n",
    "    for x in range(len(latz_0)):\n",
    "        for y in range(len(lonz_0)):\n",
    "            lat_0=latz_0[x];lat_1=latz_1[x]\n",
    "            lon_0=lonz_0[y];lon_1=lonz_1[y]\n",
    "            file_fcst = file_dic['T850_grid'][fcst_model].format(lon_0,lon_1-2,lat_1-2,lat_0)\n",
    "            file_rean = file_dic['T850_grid']['ERA5'].format(lon_0,lon_1-2,lat_1-2,lat_0)\n",
    "            file_clim_p90 = 'era51_mars_t850_79-19_24hourly_90p_lon_{}_{}_lat_{}_{}_SMOOTHED_ALL.nc'.format(lon_0,lon_1-2,lat_1-2,lat_0)\n",
    "#             file_clim_p50 = 'era51_mars_t850_79-19_24hourly_50p_lon_{}_{}_lat_{}_{}_SMOOTHED_ALL.nc'.format(lon_0,lon_1-2,lat_1-2,lat_0)\n",
    "            file_clim_p10 = 'era51_mars_t850_79-19_24hourly_10p_lon_{}_{}_lat_{}_{}_SMOOTHED_ALL.nc'.format(lon_0,lon_1-2,lat_1-2,lat_0)\n",
    "            fcst = xr.open_dataset(path+file_fcst,decode_times=False).squeeze()\n",
    "            #set fcst time data to datetime object\n",
    "            init_time_fcst = pd.Timestamp('1979-01-01')\n",
    "            fcst['time'] = [pd.Timedelta(i-fcst.time.values[0],'hours')+init_time_fcst for i in fcst.time.values]\n",
    "            fcst['lead'] = fcst['lead']//24\n",
    "            #group forecast by lead time and take daily means\n",
    "            fcst = fcst.sel(lead=slice(0,9)).groupby('lead').mean()\n",
    "            rean = xr.open_dataset(path+file_rean).squeeze()\n",
    "            if int(rean.time[0].dt.hour)!=0:\n",
    "                rean = rean.assign_coords({'time':rean.time.values - pd.Timedelta(int(rean.time[0].dt.hour),'h')})\n",
    "            #load percentile climatology. For convenience I set the data to all days in the leap year 2016. That has no further effect on the data\n",
    "            clim_p90 = xr.open_dataset(path+file_clim_p90).squeeze()\n",
    "            clim_p90['time']=pd.date_range('2016-01-01',\"2016-12-31\")\n",
    "            clim_p10 = xr.open_dataset(path+file_clim_p10).squeeze()\n",
    "            clim_p10['time']=pd.date_range('2016-01-01',\"2016-12-31\")\n",
    "            #load all temperature extremes\n",
    "            file_pers_hw = 'dates/pw_lon_{}_{}_lat_{}_{}.npy'.format(lon_0,lon_1,lat_1,lat_0)\n",
    "            file_pers_cw = 'dates/cw_lon_{}_{}_lat_{}_{}.npy'.format(lon_0,lon_1,lat_1,lat_0)\n",
    "#             file_pers_avg = 'dates/avg_p40_p60_lon_{}_{}_lat_{}_{}.npy'.format(lon_0,lon_1,lat_1,lat_0)\n",
    "            pers_hw = np.load(path+file_pers_hw,allow_pickle=True)\n",
    "            pers_cw = np.load(path+file_pers_cw,allow_pickle=True)\n",
    "#             pers_avg = np.load(path+file_pers_avg,allow_pickle=True)\n",
    "            temp_extremez = [pers_hw,pers_cw]\n",
    "            #set column names for csv file\n",
    "            columnz = ['persistent_hw','persistent_cw',\n",
    "                       'length_persistent_hw','length_persistent_cw']\n",
    "            #create index for csv file\n",
    "            index = pd.date_range(pd.Timestamp('1979-01-01'),pd.Timestamp('2019-12-31'))\n",
    "            #loop over lead days\n",
    "            lead_dayz = [5]\n",
    "            for lead_day in lead_dayz:\n",
    "                #create empty pandas dataframe\n",
    "                df = pd.DataFrame(index=index,columns=columnz,dtype=float)\n",
    "                #Loop over all extreme events\n",
    "                for j,temp_extreme in enumerate(temp_extremez):\n",
    "                    #Select persistent or short-lived warm or cold temp extreme\n",
    "                    column = columnz[j]\n",
    "                    #Loop over each individual event\n",
    "                    for i,(begin_date,end_date) in enumerate(temp_extreme):\n",
    "                        begin_date = pd.Timestamp(begin_date);end_date=pd.Timestamp(end_date)\n",
    "                        #If an event in the first few days of the datset requires a forecast before 1-12-84 skip this event\n",
    "                        if begin_date<pd.Timestamp('1979-01-01')+pd.Timedelta(lead_day,'days'):\n",
    "                            continue\n",
    "                        #define date of required forecast\n",
    "                        begin_lead_date = begin_date - pd.Timedelta(lead_day,'days')\n",
    "                        #Skip events that occur on 29,30 or 31 Oct because these days are not present in the ERA5 reforecast\n",
    "                        if np.isin(begin_lead_date,[pd.Timestamp('2014-10-29'),\n",
    "                                               pd.Timestamp('2014-10-30'),\n",
    "                                               pd.Timestamp('2014-10-31')]):\n",
    "                            continue\n",
    "                        #define date for highest lead day (last day of forecast)\n",
    "                        end_lead_date = begin_date + pd.Timedelta(9-lead_day,'days')\n",
    "                        #Calculate lead day of on last day of observed temperature extreme \n",
    "                        end_lead_day = (end_date - begin_lead_date).days\n",
    "                        #if last day of extreme event exceeds the forecast range,\n",
    "                        #I set the last day of the event on the day where the latest forecast is available\n",
    "                        if (pd.Timestamp(end_date)-pd.Timestamp(begin_date)).days > (9-lead_day): \n",
    "                            rean_sub = rean.sel(time=slice(begin_date,end_lead_date)).load()\n",
    "                        else:\n",
    "                            rean_sub = rean.sel(time=slice(begin_date,end_date)).load()\n",
    "                        #Select forecast date with subsequent lead days where event was observed\n",
    "                        fcst_sub = fcst.sel(time=begin_lead_date,lead=slice(lead_day,end_lead_day)).load()\n",
    "\n",
    "                        assert(begin_lead_date+pd.Timedelta(end_lead_day,'days')==end_date)\n",
    "                        #Calculate Mean Absolute Error of forecast\n",
    "                        MAE = float(np.abs(fcst_sub.t-rean_sub.t.values).mean().values)\n",
    "                        #The code below is a check to see whether all days in the reanalysis truly are extreme\n",
    "                        if (pd.Timestamp(end_date)-pd.Timestamp(begin_date)).days > (9-lead_day):\n",
    "                            timez = [pd.Timestamp('2016-{:02d}-{:02d}'.format(i.month,i.day)) for i in pd.date_range(begin_date,end_lead_date)]\n",
    "                        else:\n",
    "                            timez = [pd.Timestamp('2016-{:02d}-{:02d}'.format(i.month,i.day)) for i in pd.date_range(begin_date,end_date)]\n",
    "                        if j==0:\n",
    "                            clim_p90_sub = clim_p90.sel(time=timez).load()\n",
    "                            rean_bool = rean_sub.t>clim_p90_sub.t.values\n",
    "                            fcst_bool = fcst_sub.t>clim_p90_sub.t.values\n",
    "                        else:\n",
    "                            clim_p10_sub = clim_p10.sel(time=timez).load()\n",
    "                            rean_bool = rean_sub.t<clim_p10_sub.t.values\n",
    "                            fcst_bool = fcst_sub.t<clim_p10_sub.t.values\n",
    "\n",
    "                        #If this statement is true all days within the renalysis are extreme\n",
    "\n",
    "                        assert(rean_bool.values.any())\n",
    "                        if rean_bool.values.any()==False:\n",
    "                            count += 1\n",
    "                            print('this happpened {} times'.format(count))\n",
    "                        #Put all MAE values in the row with the same date as the onset of the event and in the column for the subsequent extreme\n",
    "                        df.loc[begin_date][column]=MAE\n",
    "                        #Make an extra column with the length of the reanalysis extreme length (corrected for forecast range)\n",
    "                        df.loc[begin_date]['length_'+column]=len(fcst_sub.t)\n",
    "                df = df.dropna(how='all')\n",
    "#                 df.to_csv(path+'MAE/Mean_Absolute_Error_lead_day_{}_lon_{}_{}_lat_{}_{}_{}.csv'.format(lead_day,lon_0,lon_1,\n",
    "#                                                                                            lat_1,lat_0,fcst_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
