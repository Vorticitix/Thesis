{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from my_tools import plot_dic, file_dic\n",
    "%matplotlib qt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path\n",
    "path = '/media/onno/Volume/GFS_T850/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinatez = [\n",
    "# (62,54,0,8),#Germany\n",
    "# (54,46,0,8), #Spain\n",
    "# (46,38,0,8), #Ukraine\n",
    "# (62,54,8,16),#Germany\n",
    "# (54,46,8,16), #Spain\n",
    "# (46,38,8,16), #Ukraine\n",
    "# (62,54,16,24),#Germany\n",
    "# (54,46,16,24), #Spain\n",
    "# (46,38,16,24)] #Ukraine\n",
    "# #loading GFS and ERA5 data for specific box \n",
    "lonz_0 = np.arange(-148,56.1,4,dtype=np.int64)\n",
    "lonz_1 = np.arange(-144,60.1,4,dtype=np.int64)\n",
    "latz_1 = np.arange(30,74.1,4,dtype=np.int64)\n",
    "latz_0 = np.arange(34,78.1,4,dtype=np.int64)\n",
    "lonz_0 = [int(i+360) if i<0 else int(i) for i in lonz_0]\n",
    "lonz_1 = [int(i+360) if i<=0 else int(i) for i in lonz_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose Forecast model: GFS or ERA5RF\n",
    "fcst_modelz = ['GFS','ERA5RF']\n",
    "for fcst_model in fcst_modelz:\n",
    "    for i in range(len(latz_0)):\n",
    "        for j in range(len(lonz_0)):\n",
    "            lat_0=latz_0[i];lat_1=latz_1[i]\n",
    "            lon_0=lonz_0[j];lon_1=lonz_1[j]\n",
    "            #open anomaly files\n",
    "            file_anom_p90 = 'era51_fldmean_mars_t850_79-19_24hourly_lon_{}_{}_lat_{}_{}_anom_from_smoothed_p90_ALL.nc'.format(lon_0,lon_1-2,lat_0-2,lat_1)\n",
    "            file_anom_p10 = 'era51_fldmean_mars_t850_79-19_24hourly_lon_{}_{}_lat_{}_{}_anom_from_smoothed_p10_ALL.nc'.format(lon_0,lon_1-2,lat_0-2,lat_1)\n",
    "            anom_p90 = xr.open_dataset(path+file_anom_p90).t.squeeze()\n",
    "            anom_p10 = xr.open_dataset(path+file_anom_p10).t.squeeze()\n",
    "            #Process data for warm extremes\n",
    "            #Calculate dates of persitent extremes that are 4 consecutive days or longer\n",
    "            anom_p90_spec = anom_p90 > 0\n",
    "            iszero = np.concatenate(([0], np.equal(anom_p90_spec.values, True).view(np.int8), [0]))\n",
    "            abs_diff = np.abs(np.diff(iszero))\n",
    "            # Runs start and end where absdiff is 1.\n",
    "            idxz = np.where(abs_diff == 1)[0].reshape(-1, 2)\n",
    "            idx_bool = (idxz[:,1]-idxz[:,0])>=4\n",
    "            hw_idxz = idxz[idx_bool,:]\n",
    "            hw_dates = np.empty(hw_idxz.shape,dtype=object)\n",
    "            for k,hw_idx in enumerate(hw_idxz):\n",
    "                hw_date = [str(anom_p90.time[hw_idx[0]].values),\n",
    "                           str(anom_p90.time[hw_idx[1]-1].values)]\n",
    "                hw_dates[k]=hw_date\n",
    "            np.save(path+'dates/pw_lon_{}_{}_lat_{}_{}.npy'.format(lon_0,lon_1,lat_0,lat_1),hw_dates)\n",
    "            np.savetxt(path+'dates/pw_lon_{}_{}_lat_{}_{}.txt'.format(lon_0,lon_1,lat_0,lat_1),hw_dates,fmt=\"%s\")\n",
    "            #Process data for cold extremes\n",
    "            anom_p10_spec = anom_p10 < 0\n",
    "            iszero = np.concatenate(([0], np.equal(anom_p10_spec.values, True).view(np.int8), [0]))\n",
    "            abs_diff = np.abs(np.diff(iszero))\n",
    "            # Runs start and end where absdiff is 1.\n",
    "            idxz = np.where(abs_diff == 1)[0].reshape(-1, 2)\n",
    "            idx_bool = (idxz[:,1]-idxz[:,0])>=4\n",
    "            cw_idxz = idxz[idx_bool,:]\n",
    "            cw_dates = np.empty(cw_idxz.shape,dtype=object)\n",
    "            for k,cw_idx in enumerate(cw_idxz):\n",
    "                cw_date = [str(anom_p10.time[cw_idx[0]].values),\n",
    "                           str(anom_p10.time[cw_idx[1]-1].values)]\n",
    "                cw_dates[k]=cw_date\n",
    "\n",
    "            np.save(path+'dates/cw_lon_{}_{}_lat_{}_{}.npy'.format(lon_0,lon_1,lat_0,lat_1),cw_dates)\n",
    "            np.savetxt(path+'dates/cw_lon_{}_{}_lat_{}_{}.txt'.format(lon_0,lon_1,lat_0,lat_1),cw_dates,fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
