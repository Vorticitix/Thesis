{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from my_tools import plot_dic, file_dic\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path\n",
    "path = '/media/onno/Algemeen/Thesis/GFS_T850/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading GFS and ERA5 data for specific box \n",
    "file_gfs = 'gefsrf2_fldmean_t850_control0-252h_24hourly_lon_6_12_lat_52_46.nc'\n",
    "file_era = 'era51_fldmean_mars_t850_79-19_24hourly_lon_6_12_lat_52_46.nc'\n",
    "file_clim_p90 = 'era51_mars_t850_79-19_24hourly_90p_lon_6_12_lat_52_46_SMOOTHED.nc'\n",
    "file_clim_p10 = 'era51_mars_t850_79-19_24hourly_10p_lon_6_12_lat_52_46_SMOOTHED.nc'\n",
    "gfs = xr.open_dataset(path+file_gfs,decode_times=False).squeeze()\n",
    "#set gfs time data to datetime object\n",
    "init_time_gfs = pd.Timestamp('1800-01-01')\n",
    "gfs['time'] = [pd.Timedelta(i,'hours')+init_time_gfs for i in gfs.time.values]\n",
    "gfs['lead'] = gfs['lead']//24\n",
    "#group forecast by lead time and take daily means\n",
    "gfs = gfs.sel(lead=slice(0,9)).groupby('lead').mean()\n",
    "era = xr.open_dataset(path+file_era).squeeze()\n",
    "#load percentile climatology. For convenience I set the data to all days in the leap year 2016. That has no further effect on the data\n",
    "clim_p90 = xr.open_dataset(path+file_clim_p90).squeeze()\n",
    "clim_p90['time']=pd.date_range('2016-01-01',\"2016-12-31\")\n",
    "clim_p10 = xr.open_dataset(path+file_clim_p10).squeeze()\n",
    "clim_p10['time']=pd.date_range('2016-01-01',\"2016-12-31\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General monthly Gilbert Skill Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put climatologies in list to loop over them\n",
    "climz = [clim_p90,clim_p10]\n",
    "#set and select lead day. Value must range between 0 and 9\n",
    "lead_dayz = [1,3,5,7,9]\n",
    "#make reanalysis and forecast of equal length\n",
    "df_warm = pd.DataFrame(index=np.arange(1,13),columns=['day_1','day_3','day_5','day_7','day_9'])\n",
    "df_cold = pd.DataFrame(index=np.arange(1,13),columns=['day_1','day_3','day_5','day_7','day_9'])\n",
    "#loop over heat and cold extremes\n",
    "\n",
    "for lead_day in lead_dayz:\n",
    "    gfs_lead = gfs.sel(lead=lead_day)\n",
    "    #convert time of forecast to initial time + forecast lead time\n",
    "    gfs_lead['time'] = gfs.time + pd.Timedelta(lead_day,'days')\n",
    "    era_lead = era.sel(time=slice(pd.Timestamp('1984-12-{:02d}'.format(lead_day+1)),\n",
    "                             pd.Timestamp('2019-11-30')))\n",
    "    gfs_lead = gfs_lead.sel(time=slice(pd.Timestamp('1984-12-{:02d}'.format(lead_day+1)),\n",
    "                             pd.Timestamp('2019-11-30')))\n",
    "    for j,clim in enumerate(climz):\n",
    "        column = columnz[j]\n",
    "        #calculate anomalies from climatoogy: see my_tools.py for more documentation\n",
    "        era_anom = my_tools.calculate_anomalies(era_lead,clim)    \n",
    "        gfs_anom = my_tools.calculate_anomalies(gfs_lead,clim)\n",
    "\n",
    "        if j ==0:\n",
    "            #convert anomalies to boolean array. If temperature is extreme than value is converted to True\n",
    "            era_bool = era_anom.t>0\n",
    "            gfs_bool = gfs_anom.t>0\n",
    "            #fill in contingency table and group all values by month\n",
    "            hits = (era_bool & gfs_bool).astype(np.int64).groupby('time.month').sum()\n",
    "            miss = ((~gfs_bool)&(era_bool)).astype(np.int64).groupby('time.month').sum()\n",
    "            false_alarm = ((gfs_bool)&(~era_bool)).astype(np.int64).groupby('time.month').sum()\n",
    "            non_event = ((~gfs_bool)&(~era_bool)).astype(np.int64).groupby('time.month').sum()\n",
    "            #caluclate Gilbert Skill Score. See my_tools.py for more documentation\n",
    "            GSS = my_tools.gilbert_skill_score(hits,miss,false_alarm,non_event)\n",
    "            #Write result to csv file\n",
    "            df_warm['day_{}'.format(lead_day)]=pd.Series(GSS,index=np.arange(1,13))\n",
    "        else:\n",
    "            #convert anomalies to boolean array. If temperature is extreme than value is converted to True\n",
    "            era_bool = era_anom.t<0\n",
    "            gfs_bool = gfs_anom.t<0\n",
    "            #fill in contingency table and group all values by month\n",
    "            hits = (era_bool & gfs_bool).astype(np.int64).groupby('time.month').sum()\n",
    "            miss = ((~gfs_bool)&(era_bool)).astype(np.int64).groupby('time.month').sum()\n",
    "            false_alarm = ((gfs_bool)&(~era_bool)).astype(np.int64).groupby('time.month').sum()\n",
    "            non_event = ((~gfs_bool)&(~era_bool)).astype(np.int64).groupby('time.month').sum()\n",
    "            #caluclate Gilbert Skill Score. See my_tools.py for more documentation\n",
    "            GSS = my_tools.gilbert_skill_score(hits,miss,false_alarm,non_event)\n",
    "            #Write result to csv file\n",
    "            df_cold['day_{}'.format(lead_day)]=pd.Series(GSS,index=np.arange(1,13))\n",
    "df_warm.to_csv(path+'GSS/GSS_general_warm.csv')\n",
    "df_cold.to_csv(path+'GSS/GSS_general_cold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific heat waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all heat extremes\n",
    "file_pers_hw = 'persistent_heatwaves_lon_6_12_lat_52_46.npy'\n",
    "file_pers_cw = 'persistent_coldwaves_lon_6_12_lat_52_46.npy'\n",
    "file_short_hw = 'short_heatwaves_lon_6_12_lat_52_46.npy'\n",
    "file_short_cw = 'short_coldwaves_lon_6_12_lat_52_46.npy'\n",
    "pers_hw = np.load(path+file_pers_hw)\n",
    "pers_cw = np.load(path+file_pers_cw)\n",
    "short_hw = np.load(path+file_short_hw)\n",
    "short_cw = np.load(path+file_short_cw)\n",
    "temp_extremez = [pers_hw,short_hw,pers_cw,short_cw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caluclate GSS for every single event and save overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnz = ['persistent_hw','short_hw','persistent_cw','short_cw',]\n",
    "index = pd.date_range(pd.Timestamp('1984-12-01'),pd.Timestamp('2019-11-30'))\n",
    "df = pd.DataFrame(index=index,columns=columnz,dtype=float)\n",
    "lead_dayz = [1,3,5,7,9]\n",
    "for lead_day in lead_dayz:\n",
    "    for j,temp_extreme in enumerate(temp_extremez):\n",
    "        column = columnz[j]\n",
    "        for i,date in enumerate(temp_extreme[:,0]):\n",
    "            if date<pd.Timestamp('1984-12-01')+pd.Timedelta(lead_day,'days'):\n",
    "                continue\n",
    "            begin_date = date - pd.Timedelta(lead_day,'days')\n",
    "            end_date = date + pd.Timedelta(9-lead_day,'days')\n",
    "            era_sub = era.sel(time=slice(begin_date,end_date)).load()\n",
    "            gfs_sub = gfs.sel(time=begin_date).load()\n",
    "            timez = [pd.Timestamp('2016-{:02d}-{:02d}'.format(i.month,i.day)) for i in pd.date_range(begin_date,end_date)]\n",
    "            if j<2:\n",
    "                clim_p90_sub = clim_p90.sel(time=timez).load()\n",
    "                era_bool = era_sub.t>clim_p90_sub.t.values\n",
    "                gfs_bool = gfs_sub.t>clim_p90_sub.t.values\n",
    "            else:\n",
    "                clim_p10_sub = clim_p10.sel(time=timez).load()\n",
    "                era_bool = era_sub.t<clim_p10_sub.t.values\n",
    "                gfs_bool = gfs_sub.t<clim_p10_sub.t.values\n",
    "            hits = (era_bool & gfs_bool.values).astype(np.int64).sum()\n",
    "            miss = ((~gfs_bool)&(era_bool.values)).astype(np.int64).sum()\n",
    "            false_alarm = ((gfs_bool)&(~era_bool.values)).astype(np.int64).sum()\n",
    "            non_event = ((~gfs_bool)&(~era_bool.values)).astype(np.int64).sum()            \n",
    "            GSS = my_tools.gilbert_skill_score(hits,miss,false_alarm,non_event)\n",
    "            df.loc[date][column]=GSS\n",
    "\n",
    "    df = df.dropna(how='all')\n",
    "    df.to_csv(path+'GSS/Gilbert_Skill_Score_lead_day_{}.csv'.format(lead_day))\n",
    "#     df_month = df.groupby(df.index.month,dropna=True).mean()\n",
    "#     df_month.to_csv(path+'GSS/Gilbert_Skill_Score_Monthly_Mean_lead_day_{}.csv'.format(lead_day))\n",
    "df_count = df.groupby(df.index.month,dropna=True).count()\n",
    "df_count.to_csv(path+'GSS/Temp_extremes_count.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate GSS based on monthly grouped contingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onno/miniconda3/envs/thesis/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "columnz = ['persistent_hw','short_hw','persistent_cw','short_cw',]\n",
    "index = pd.date_range(pd.Timestamp('1984-12-01'),pd.Timestamp('2019-11-30'))\n",
    "df = pd.DataFrame(index=np.arange(1,13),columns=columnz,dtype=float)\n",
    "lead_dayz = [1,3,5,7,9]\n",
    "for lead_day in lead_dayz:\n",
    "    for j,temp_extreme in enumerate(temp_extremez):\n",
    "        column = columnz[j]\n",
    "        df_contingency = pd.DataFrame(columns=['hits','miss','false_alarm','non_event'])\n",
    "        for i,date in enumerate(temp_extreme[:,0]):\n",
    "            if date<pd.Timestamp('1984-12-01')+pd.Timedelta(lead_day,'days'):\n",
    "                continue\n",
    "            begin_date = date - pd.Timedelta(lead_day,'days')\n",
    "            end_date = date + pd.Timedelta(9-lead_day,'days')\n",
    "            era_sub = era.sel(time=slice(begin_date,end_date)).load()\n",
    "            gfs_sub = gfs.sel(time=begin_date).load()\n",
    "            timez = [pd.Timestamp('2016-{:02d}-{:02d}'.format(i.month,i.day)) for i in pd.date_range(begin_date,end_date)]\n",
    "            if j<2:\n",
    "                clim_p90_sub = clim_p90.sel(time=timez).load()\n",
    "                era_bool = era_sub.t>clim_p90_sub.t.values\n",
    "                gfs_bool = gfs_sub.t>clim_p90_sub.t.values\n",
    "            else:\n",
    "                clim_p10_sub = clim_p10.sel(time=timez).load()\n",
    "                era_bool = era_sub.t<clim_p10_sub.t.values\n",
    "                gfs_bool = gfs_sub.t<clim_p10_sub.t.values\n",
    "            hits = (era_bool & gfs_bool.values).astype(np.int64).sum()\n",
    "            miss = ((~gfs_bool)&(era_bool.values)).astype(np.int64).sum()\n",
    "            false_alarm = ((gfs_bool)&(~era_bool.values)).astype(np.int64).sum()\n",
    "            non_event = ((~gfs_bool)&(~era_bool.values)).astype(np.int64).sum()    \n",
    "            df_contingency.loc[date] = [int(hits),int(miss),int(false_alarm),int(non_event)]\n",
    "\n",
    "        df_contingency_month = df_contingency.groupby(df_contingency.index.month).sum()\n",
    "        GSS = my_tools.gilbert_skill_score_dataframe(df_contingency_month)\n",
    "        df[column]=GSS\n",
    "    df.to_csv(path+'GSS/GSS_Temp_Extremes_Monthly_Grouped_lead_day_{}.csv'.format(lead_day))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate GSS based on seasonally grouped contingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lead Day is 1\n",
      "     persistent_hw  short_hw  persistent_cw  short_cw\n",
      "DJF       0.502900  0.449966       0.483407  0.495750\n",
      "JJA       0.418036  0.480549       0.473479  0.558146\n",
      "MAM       0.370017  0.436537       0.452485  0.460602\n",
      "SON       0.483156  0.474639       0.509434  0.504272\n",
      " Lead Day is 3\n",
      "     persistent_hw  short_hw  persistent_cw  short_cw\n",
      "DJF       0.376064  0.425636       0.448351  0.318102\n",
      "JJA       0.467139  0.347509       0.419476  0.373443\n",
      "MAM       0.255781  0.336178       0.430113  0.387298\n",
      "SON       0.423699  0.329568       0.308949  0.436907\n",
      " Lead Day is 5\n",
      "     persistent_hw  short_hw  persistent_cw  short_cw\n",
      "DJF       0.239121  0.349593       0.347947  0.247583\n",
      "JJA       0.382122  0.302763       0.213424  0.235503\n",
      "MAM       0.228985  0.262387       0.298077  0.245261\n",
      "SON       0.261954  0.271464       0.288873  0.328387\n",
      " Lead Day is 7\n",
      "     persistent_hw  short_hw  persistent_cw  short_cw\n",
      "DJF       0.278046  0.268758       0.319754  0.201078\n",
      "JJA       0.119264  0.243379       0.173864  0.263627\n",
      "MAM       0.137466  0.327782       0.276316  0.292120\n",
      "SON       0.212008  0.217328       0.173522  0.297592\n",
      " Lead Day is 9\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onno/miniconda3/envs/thesis/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "columnz = ['persistent_hw','short_hw','persistent_cw','short_cw',]\n",
    "index = pd.date_range(pd.Timestamp('1984-12-01'),pd.Timestamp('2019-11-30'))\n",
    "df = pd.DataFrame(index=['DJF','JJA','MAM','SON'],columns=columnz,dtype=float)\n",
    "month_to_season_lu = np.array([\n",
    "    None,\n",
    "    'DJF', 'DJF',\n",
    "    'MAM', 'MAM', 'MAM',\n",
    "    'JJA', 'JJA', 'JJA',\n",
    "    'SON', 'SON', 'SON',\n",
    "    'DJF'\n",
    "])\n",
    "lead_dayz = [1,3,5,7,9]\n",
    "for lead_day in lead_dayz:\n",
    "    print(' Lead Day is {}'.format(lead_day))\n",
    "    for j,temp_extreme in enumerate(temp_extremez):\n",
    "        column = columnz[j]\n",
    "        df_contingency = pd.DataFrame(columns=['hits','miss','false_alarm','non_event'])\n",
    "        for i,date in enumerate(temp_extreme[:,0]):\n",
    "            if date<pd.Timestamp('1984-12-01')+pd.Timedelta(lead_day,'days'):\n",
    "                continue\n",
    "            begin_date = date - pd.Timedelta(lead_day,'days')\n",
    "            end_date = date + pd.Timedelta(9-lead_day,'days')\n",
    "            era_sub = era.sel(time=slice(begin_date,end_date)).load()\n",
    "            gfs_sub = gfs.sel(time=begin_date).load()\n",
    "            timez = [pd.Timestamp('2016-{:02d}-{:02d}'.format(i.month,i.day)) for i in pd.date_range(begin_date,end_date)]\n",
    "            if j<2:\n",
    "                clim_p90_sub = clim_p90.sel(time=timez).load()\n",
    "                era_bool = era_sub.t>clim_p90_sub.t.values\n",
    "                gfs_bool = gfs_sub.t>clim_p90_sub.t.values\n",
    "            else:\n",
    "                clim_p10_sub = clim_p10.sel(time=timez).load()\n",
    "                era_bool = era_sub.t<clim_p10_sub.t.values\n",
    "                gfs_bool = gfs_sub.t<clim_p10_sub.t.values\n",
    "            hits = (era_bool & gfs_bool.values).astype(np.int64).sum()\n",
    "            miss = ((~gfs_bool)&(era_bool.values)).astype(np.int64).sum()\n",
    "            false_alarm = ((gfs_bool)&(~era_bool.values)).astype(np.int64).sum()\n",
    "            non_event = ((~gfs_bool)&(~era_bool.values)).astype(np.int64).sum()    \n",
    "            df_contingency.loc[date] = [int(hits),int(miss),int(false_alarm),int(non_event)]\n",
    "        if (lead_day==9)&(j==0):\n",
    "            sys.exit()\n",
    "\n",
    "        df_contingency_month = df_contingency.groupby(month_to_season_lu[df_contingency.index.month]).sum()\n",
    "        GSS = my_tools.gilbert_skill_score_dataframe(df_contingency_month)\n",
    "        df[column]=GSS\n",
    "    print(df)\n",
    "#     df.to_csv(path+'GSS/GSS_Temp_Extremes_Seasonally_Grouped_lead_day_{}.csv'.format(lead_day))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onno/miniconda3/envs/thesis/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "lead_dayz = [1,3,5,7,9]\n",
    "file = 'GSS/Gilbert_Skill_Score_lead_day_{}.csv'\n",
    "month_to_season_lu = np.array([\n",
    "    None,\n",
    "    'DJF', 'DJF',\n",
    "    'MAM', 'MAM', 'MAM',\n",
    "    'JJA', 'JJA', 'JJA',\n",
    "    'SON', 'SON', 'SON',\n",
    "    'DJF'\n",
    "])\n",
    "for lead_day in lead_dayz:\n",
    "    df = pd.read_csv(path+file.format(lead_day),index_col=0)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df_seasonally = df.groupby(month_to_season_lu[df.index.month]).mean()\n",
    "    sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
