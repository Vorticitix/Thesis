{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quality-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from my_tools import file_dic, plot_dic\n",
    "from cmap import ncl_colormap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "combined-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path for \n",
    "path_gen = '/media/onno/Algemeen/Thesis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beginning-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load RWP property files\n",
    "file_rean_env = path_gen + file_dic['envelope']['ERA5']\n",
    "file_rean_cp = path_gen + file_dic['phasespeed']['ERA5']\n",
    "file_GFS_env = path_gen + file_dic['envelope']['GFS']\n",
    "file_GFS_cp = path_gen + file_dic['phasespeed']['GFS']\n",
    "file_ERA5RF_env = path_gen + file_dic['envelope']['ERA5RF']\n",
    "file_ERA5RF_cp = path_gen + file_dic['phasespeed']['ERA5RF']\n",
    "\n",
    "rean_env_gen = xr.open_dataset(file_rean_env).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_cp_gen = xr.open_dataset(file_rean_cp).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_env_gen =  rean_env_gen.assign_coords(longitude=(((rean_env_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_cp_gen =  rean_cp_gen.assign_coords(longitude=(((rean_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "\n",
    "rean_env_gen=rean_env_gen.rename({'longitude':'lon'});rean_env_gen=rean_env_gen.rename({'latitude':'lat'})\n",
    "rean_cp_gen=rean_cp_gen.rename({'longitude':'lon'});rean_cp_gen=rean_cp_gen.rename({'latitude':'lat'})\n",
    "# rean_env_gen = rean_env_gen.sel(time=[bool(i) for i in rean_env_gen.time.dt.hour%24==0])\n",
    "# rean_cp_gen = rean_cp_gen.sel(time=[bool(i) for i in rean_cp_gen.time.dt.hour%24==0])\n",
    "\n",
    "ERA5RF_env_gen = xr.open_dataset(file_ERA5RF_env,decode_times=False).squeeze()\n",
    "GFS_env_gen = xr.open_dataset(file_GFS_env,decode_times=False).squeeze()\n",
    "ERA5RF_cp_gen = xr.open_dataset(file_ERA5RF_cp,decode_times=False).squeeze()\n",
    "GFS_cp_gen = xr.open_dataset(file_GFS_cp,decode_times=False).squeeze()\n",
    "\n",
    "GFS_init_time = pd.Timestamp('1800-01-01')\n",
    "ERA5RF_init_time = pd.Timestamp('1900-01-01')\n",
    "GFS_env_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_env_gen.time.values]\n",
    "GFS_cp_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_cp_gen.time.values]\n",
    "ERA5RF_env_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_env_gen.time.values]\n",
    "ERA5RF_cp_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_cp_gen.time.values]\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'lon':'longitude','lat':'latitude'}); GFS_cp_gen = GFS_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'lon':'longitude','lat':'latitude'}); ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "GFS_env_gen = GFS_env_gen.assign_coords(longitude=(((GFS_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "GFS_cp_gen = GFS_cp_gen.assign_coords(longitude=(((GFS_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.assign_coords(longitude=(((ERA5RF_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.assign_coords(longitude=(((ERA5RF_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "# GFS_env_gen = GFS_env_gen.sel(lead=GFS_env_gen.lead.values[[bool(i) for i in GFS_env_gen.lead%24==0]])\n",
    "# GFS_cp_gen = GFS_cp_gen.sel(lead=GFS_cp_gen.lead.values[[bool(i) for i in GFS_cp_gen.lead%24==0]])\n",
    "# ERA5RF_env_gen = ERA5RF_env_gen.sel(lead=ERA5RF_env_gen.lead.values[[bool(i) for i in ERA5RF_env_gen.lead%24==0]])\n",
    "# ERA5RF_cp_gen = ERA5RF_cp_gen.sel(lead=ERA5RF_cp_gen.lead.values[[bool(i) for i in ERA5RF_cp_gen.lead%24==0]])\n",
    "\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "GFS_cp_gen = GFS_cp_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-intensity",
   "metadata": {},
   "source": [
    "Forecast Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incoming-camel",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/onno/Algemeen/Thesis/GFS_T850/rank_forecast/seasonal/good_forecasts_split_data_persistent_hw_lon_6_14_lat_54_46_MAM_GFS.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7a1ea2d8e8e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                                                                                   \u001b[0mlon_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlon_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                                                                                     season,model),\n\u001b[0;32m---> 33\u001b[0;31m                                      index_col=0)\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/onno/Algemeen/Thesis/GFS_T850/rank_forecast/seasonal/good_forecasts_split_data_persistent_hw_lon_6_14_lat_54_46_MAM_GFS.txt'"
     ]
    }
   ],
   "source": [
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_data'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = ['MAM','JJA','SON','DJF']\n",
    "lead_day = 5\n",
    "for i,model in enumerate(modelz):\n",
    "    fcst_env_gen = fcstz_env[i]\n",
    "    fcst_cp_gen = fcstz_cp[i]\n",
    "    for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "        list_df = []\n",
    "        for season in seasonz:\n",
    "            for event in eventz:\n",
    "                datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                for rank in rankz:\n",
    "\n",
    "\n",
    "                    df = pd.read_csv(path_gen+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "                                                                                                                    event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model),\n",
    "                                     index_col=0)\n",
    "                    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                    lon_0_RWP = lon_0 - 8\n",
    "                    lon_1_RWP = lon_1 + 6\n",
    "                    lat_0_RWP = lat_0 + 6\n",
    "                    lat_1_RWP = lat_1 - 8\n",
    "                    if lon_0_RWP>180:\n",
    "                        lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                    all_meanz_env = []\n",
    "                    all_meanz_cp = []\n",
    "                    for date in df.index:\n",
    "                        index = int(np.squeeze(np.where(datez_event[:,0]==date)))\n",
    "                        date_event = datez_event[index]\n",
    "                        begin_date_event,end_date_event = date_event\n",
    "                        begin_date_fcst = begin_date_event - pd.Timedelta(,'days')\n",
    "                        end_date_fcst = begin_date_fcst + pd.Timedelta(9,'days')\n",
    "\n",
    "                        if end_date_event>end_date_fcst:\n",
    "                            end_date_event = end_date_fcst\n",
    "                        end_lead_day = (end_date_event - begin_date_fcst).days\n",
    "                        rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event))\n",
    "                        fcst_env_sub = fcst_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day,end_lead_day))\n",
    "                        diff_fcst_env = fcst_env_sub - rean_env_sub.v.values\n",
    "\n",
    "                        rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event))\n",
    "                        fcst_cp_sub = fcst_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day,end_lead_day))\n",
    "                        diff_fcst_cp = fcst_cp_sub - rean_cp_sub.v.values\n",
    "                        all_meanz_env.append(diff_fcst_env.mean(dim='lead'))\n",
    "                        all_meanz_cp.append(diff_fcst_cp.mean(dim='lead'))\n",
    "                    if len(all_meanz_cp)>0:\n",
    "                        diff_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "                        diff_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "                        diff_env_mean = my_tools.weighted_average_area_3D(diff_env_sub_all,variable='envelope')\n",
    "                        diff_cp_median = diff_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "                        .where((diff_cp_sub_all.v.count(dim=['lat','lon'])/len(diff_cp_sub_all.lat)**2)>=.2)\n",
    "                        \n",
    "                        df.loc[:,'envelope'] = diff_env_mean\n",
    "                        df.loc[:,'phasespeed'] = diff_cp_median\n",
    "                        df.loc['mean'] = df.mean().values\n",
    "                    df.to_csv(path+'fcst_RWP_properties/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model))\n",
    "                    if len(all_meanz_cp)==0:\n",
    "                        df.loc[rank]=[np.nan,np.nan]\n",
    "                        df.loc[:,'envelope']=np.nan\n",
    "                        df.loc[:,'phasespeed']=np.nan\n",
    "                    else:\n",
    "                        df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "                    list_df.append(df)\n",
    "            with open(path+'fcst_RWP_properties/seasonal/forecasts_errors{}_lon_{}_{}_lat_{}_{}_RWP_total_{}_lead_day_{}.txt'.format(dataset_type,\n",
    "                                                                                                                         lon_0,lon_1,lat_0,lat_1,model,lead_day),'w') as foo:\n",
    "                for df in list_df:\n",
    "                    foo.write(df.to_string())\n",
    "                    foo.write('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-rescue",
   "metadata": {},
   "source": [
    "Absolute RWP property values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "immune-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_dataset'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_day = 5\n",
    "for i,model in enumerate(modelz):\n",
    "    fcst_env_gen = fcstz_env[i]\n",
    "    fcst_cp_gen = fcstz_cp[i]\n",
    "    for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "        list_df = []\n",
    "        for season in seasonz:\n",
    "            for event in eventz:\n",
    "                datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "#                 for rank in rankz:\n",
    "\n",
    "\n",
    "#                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "#                                                                                                                     event,\n",
    "#                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "#                                                                                                                     season,model),\n",
    "#                                      index_col=0)\n",
    "#                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                lon_0_RWP = lon_0 - 8\n",
    "                lon_1_RWP = lon_1 + 6\n",
    "                lat_0_RWP = lat_0 + 6\n",
    "                lat_1_RWP = lat_1 - 8\n",
    "                if lon_0_RWP>180:\n",
    "                    lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                all_meanz_env = []\n",
    "                all_meanz_cp = []\n",
    "                for date_event in datez_event:\n",
    "                    begin_date_event,end_date_event = date_event\n",
    "                    rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "\n",
    "                    rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "                    all_meanz_env.append(rean_env_sub.mean(dim='time'))\n",
    "                    all_meanz_cp.append(rean_cp_sub.mean(dim='time'))\n",
    "                rean_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "                rean_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "                rean_env_median = rean_env_sub_all.median(dim=['lat','lon']).v\n",
    "                rean_cp_median = rean_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "                .where((rean_cp_sub_all.v.count(dim=['lat','lon'])/len(rean_cp_sub_all.lat)**2)>=.2)\n",
    "                \n",
    "                rean_env_standardized = (rean_env_median - rean_env_median.mean())/rean_env_median.std()\n",
    "                rean_cp_standardized = (rean_cp_median - rean_cp_median.mean())/rean_cp_median.std()\n",
    "\n",
    "                df_norm = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed'])\n",
    "                df_norm.loc[:,'envelope'] = rean_env_standardized\n",
    "                df_norm.loc[:,'phasespeed'] = rean_cp_standardized\n",
    "                df_norm.loc['mean'] = df.mean().values\n",
    "                \n",
    "                df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed'])\n",
    "                df_av.loc[:,'envelope'] = rean_env_median\n",
    "                df_av.loc[:,'phasespeed'] = rean_cp_median\n",
    "                good_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model),\n",
    "                                     index_col=0).index\n",
    "                good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model),\n",
    "                                     index_col=0).index\n",
    "                bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                df_norm_good = df_norm[df_norm.index.isin(good_forecasts)]\n",
    "                df_norm_bad = df_norm[df_norm.index.isin(bad_forecasts)]\n",
    "                df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "                \n",
    "                df_av_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_av_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "#                 if len(all_meanz_cp)==0:\n",
    "#                     df.loc[rank]=[np.nan,np.nan]\n",
    "#                     df.loc[:,'envelope']=np.nan\n",
    "#                     df.loc[:,'phasespeed']=np.nan\n",
    "#                 else:\n",
    "#                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "#                 list_df.append(df)\n",
    "#             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "#                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "#                 for df in list_df:\n",
    "#                     foo.write(df.to_string())\n",
    "#                     foo.write('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "outdoor-theme",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,12,12) (20,12,12) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f040fa25d733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m                         fcst_env_sub = fcst_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n\u001b[1;32m     61\u001b[0m                                                     time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0mdiff_fcst_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcst_env_sub\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrean_env_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                         rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5156\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_binary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_calculate_binary_op\u001b[0;34m(self, f, other, join, inplace)\u001b[0m\n\u001b[1;32m   5227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5228\u001b[0m             \u001b[0mother_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"variable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5229\u001b[0;31m             \u001b[0mnew_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_variable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5230\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5231\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5228\u001b[0m             \u001b[0mother_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"variable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5229\u001b[0;31m             \u001b[0mnew_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_variable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5230\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5231\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2194\u001b[0m                 new_data = (\n\u001b[1;32m   2195\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2197\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,12,12) (20,12,12) "
     ]
    }
   ],
   "source": [
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_dataset'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_day = 5\n",
    "for i,model in enumerate(modelz):\n",
    "    fcst_env_gen = fcstz_env[i]\n",
    "    fcst_cp_gen = fcstz_cp[i]\n",
    "    for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "        list_df = []\n",
    "        for season in seasonz:\n",
    "            for event in eventz:\n",
    "                datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "#                 for rank in rankz:\n",
    "\n",
    "\n",
    "#                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "#                                                                                                                     event,\n",
    "#                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "#                                                                                                                     season,model),\n",
    "#                                      index_col=0)\n",
    "#                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                lon_0_RWP = lon_0 - 8\n",
    "                lon_1_RWP = lon_1 + 6\n",
    "                lat_0_RWP = lat_0 + 6\n",
    "                lat_1_RWP = lat_1 - 8\n",
    "                if lon_0_RWP>180:\n",
    "                    lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                all_meanz_env = []\n",
    "                all_meanz_cp = []\n",
    "                df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed'])\n",
    "                for date_event in datez_event:\n",
    "                    begin_date_event,end_date_event = date_event\n",
    "                    begin_date_fcst = begin_date_event - pd.Timedelta(lead_day*24,'hours')\n",
    "                    end_date_fcst = begin_date_fcst + pd.Timedelta(9*24,'hours')\n",
    "\n",
    "                    if end_date_event>end_date_fcst:\n",
    "                        end_date_event = end_date_fcst\n",
    "                    end_lead_hours_object = ((end_date_event - begin_date_fcst) + pd.Timedelta(18,'h'))\n",
    "                    end_lead_hours = end_lead_hours_object.days*24 + end_lead_hours_object.seconds//3600 \n",
    "                    try:\n",
    "                        rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                        fcst_env_sub = fcst_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                        diff_fcst_env = fcst_env_sub - rean_env_sub.v.values\n",
    "\n",
    "                        rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                        fcst_cp_sub = fcst_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                        diff_fcst_cp = fcst_cp_sub - rean_cp_sub.v.values\n",
    "\n",
    "                        diff_env_median = diff_fcst_env.median(dim=['lat','lon']).v\n",
    "                        diff_cp_median = diff_fcst_cp.median(dim=['lat','lon']).v\\\n",
    "                        .where((diff_fcst_cp.v.count(dim=['lat','lon'])/len(diff_fcst_cp.lat)**2)>=.2)\n",
    "\n",
    "                        df_av.loc[begin_date_event,'envelope'] = float(diff_env_median.mean())\n",
    "                        df_av.loc[begin_date_event,'phasespeed'] = float(diff_cp_median.mean())\n",
    "                    except KeyError:\n",
    "                        df.loc[begin_date_event,'envelope'] = np.nan\n",
    "                        df.loc[begin_date_event,'phasespeed'] = np.nan\n",
    "                df_norm = (df_av - df_av.mean())/df_av.std()\n",
    "    \n",
    "#                     all_meanz_env.append(diff_fcst_env.mean(dim='lead'))\n",
    "#                     all_meanz_cp.append(diff_fcst_cp.mean(dim='lead'))\n",
    "#                 diff_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "#                 diff_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "#                 diff_env_median = diff_env_sub_all.median(dim=['lat','lon']).v\n",
    "#                 diff_cp_median = diff_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "#                 .where((diff_cp_sub_all.v.count(dim=['lat','lon'])/len(diff_cp_sub_all.lat)**2)>=.2)\n",
    "\n",
    "                \n",
    "\n",
    "#                 df.loc[:,'envelope'] = diff_env_standardized\n",
    "#                 df.loc[:,'phasespeed'] = diff_cp_standardized\n",
    "#                 df.loc['mean'] = df.mean().values\n",
    "                good_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model),\n",
    "                                     index_col=0).index\n",
    "                good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model),\n",
    "                                     index_col=0).index\n",
    "                bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "                df_norm_good = df_norm[df_av.index.isin(good_forecasts)]\n",
    "                df_norm_bad = df_norm[df_av.index.isin(bad_forecasts)]                \n",
    "                df_av_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_av_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "#                 if len(all_meanz_cp)==0:\n",
    "#                     df.loc[rank]=[np.nan,np.nan]\n",
    "#                     df.loc[:,'envelope']=np.nan\n",
    "#                     df.loc[:,'phasespeed']=np.nan\n",
    "#                 else:\n",
    "#                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "#                 list_df.append(df)\n",
    "#             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "#                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "#                 for df in list_df:\n",
    "#                     foo.write(df.to_string())\n",
    "#                     foo.write('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-cologne",
   "metadata": {},
   "source": [
    "Combine all forecast errors for each type of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bound-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "event_titlez = ['Persistent Warm Extreme','Persistent Cold Extreme',\n",
    "               'Short-Lived Warm Extreme','Short-Lived Cold Extreme']\n",
    "rankz = ['good','bad']\n",
    "seasonz = ['DJF','JJA']\n",
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)]\n",
    "path = '/media/onno/Algemeen/Thesis/fcst_RWP_properties/'\n",
    "file = '{}_forecasts_error_split_dataset_{}_lon_{}_{}_lat_{}_{}_{}_GFS.txt'\n",
    "\n",
    "for i,event in enumerate(eventz):\n",
    "    for season in seasonz:\n",
    "        env_error_good = np.array([])\n",
    "        env_error_bad = np.array([])\n",
    "        cp_error_good = np.array([])\n",
    "        cp_error_bad = np.array([])\n",
    "        for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "            df_good = pd.read_csv(path+file.format('good',event,\n",
    "                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                  season),index_col=0).drop('mean')\n",
    "            df_bad = pd.read_csv(path+file.format('bad',event,\n",
    "                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                      season),index_col=0).drop('mean') \n",
    "            env_error_good = np.concatenate((env_error_good,df_good['envelope'].values))\n",
    "            env_error_bad = np.concatenate((env_error_bad,df_bad['envelope'].values))\n",
    "            cp_error_good = np.concatenate((cp_error_good,df_good['phasespeed'].values))\n",
    "            cp_error_bad = np.concatenate((cp_error_bad,df_bad['phasespeed'].values))\n",
    "\n",
    "        fig,axz = plt.subplots(1,2,figsize=(16,9))\n",
    "        bins = np.linspace(-10,10,21)\n",
    "        ax1 = axz.flat[0]\n",
    "        ax1.hist([env_error_good,env_error_bad],bins,label=['good','bad'],density=True)\n",
    "        ax1.set_title('Envelope')\n",
    "        ax1.set_xticks(np.linspace(-10,10,11))\n",
    "        ax1.set_xlabel('Forecast Error E (m/s)')\n",
    "        ax1.text(0.01,0.99,'$μ_{{good}}$ = {:.2f} \\n$μ_{{bad}}$ = {:.2f} \\n$σ_{{good}}$ = {:.2f} \\n$σ_{{bad}}$ = {:.2f}'\\\n",
    "                .format(np.mean(env_error_good),np.mean(env_error_bad),np.std(env_error_good),np.std(env_error_bad)),\n",
    "                transform = ax1.transAxes,verticalalignment='top',horizontalalignment='left')\n",
    "        ax2 = axz.flat[1]\n",
    "        ax2.hist([cp_error_good,cp_error_bad],bins,label=['good','bad'],density=True)\n",
    "        ax2.set_title('Phasespeed')\n",
    "        ax2.set_xticks(np.linspace(-10,10,11))\n",
    "        ax2.set_xlabel('Forecast Error Cp (m/s)')\n",
    "        ax2.text(0.01,0.99,'$μ_{{good}}$ = {:.2f} \\n$μ_{{bad}}$ = {:.2f} \\n$σ_{{good}}$ = {:.2f} \\n$σ_{{bad}}$ = {:.2f}'\\\n",
    "        .format(np.nanmean(cp_error_good),np.nanmean(cp_error_bad),np.nanstd(cp_error_good),np.nanstd(cp_error_bad)),\n",
    "        transform = ax2.transAxes,verticalalignment='top',horizontalalignment='left')\n",
    "        ax2.legend()\n",
    "        fig.suptitle('Forecast Error {} {} GFS'.format(event_titlez[i],season))\n",
    "        fig.savefig(path + 'histogram/{}_{}_GFS'.format(event,season))\n",
    "        plt.close(fig)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-attachment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
