{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from my_tools import file_dic, plot_dic\n",
    "from cmap import ncl_colormap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "%matplotlib qt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path for \n",
    "path_gen = '/home/onno/Thesis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/home/onno/Thesis/era51_mars_env_wledit2000-10000_latavg_v300_79-19_6hourly_smoothed.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/onno/Thesis/era51_mars_env_wledit2000-10000_latavg_v300_79-19_6hourly_smoothed.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a7a28706884e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrean_env_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_rean_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mrean_cp_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_rean_cp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrean_t850_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_rean_t850\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_remote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"netcdf4\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             store = backends.NetCDF4DataStore.open(\n\u001b[0m\u001b[1;32m    509\u001b[0m                 \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbackend_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         )\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;31m# ensure file doesn't get overriden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/home/onno/Thesis/era51_mars_env_wledit2000-10000_latavg_v300_79-19_6hourly_smoothed.nc'"
     ]
    }
   ],
   "source": [
    "#load RWP property files\n",
    "file_rean_env = path_gen + file_dic['envelope']['ERA5']\n",
    "file_rean_cp = path_gen + file_dic['phasespeed']['ERA5']\n",
    "file_rean_t850 = path_gen + file_dic['T850']['ERA5']\n",
    "file_GFS_env = path_gen + file_dic['envelope']['GFS']\n",
    "file_GFS_cp = path_gen + file_dic['phasespeed']['GFS']\n",
    "file_GFS_t850 = path_gen + file_dic['T850']['GFS']\n",
    "file_ERA5RF_env = path_gen + file_dic['envelope']['ERA5RF']\n",
    "file_ERA5RF_cp = path_gen + file_dic['phasespeed']['ERA5RF']\n",
    "file_ERA5RF_t850 = path_gen + file_dic['T850']['ERA5RF']\n",
    "\n",
    "\n",
    "rean_env_gen = xr.open_dataset(file_rean_env).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_cp_gen = xr.open_dataset(file_rean_cp).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_t850_gen = xr.open_dataset(file_rean_t850).sel(latitude=slice(90,0)).squeeze()\n",
    "\n",
    "rean_env_gen =  rean_env_gen.assign_coords(longitude=(((rean_env_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_cp_gen =  rean_cp_gen.assign_coords(longitude=(((rean_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_t850_gen = rean_t850_gen.assign_coords(longitude=(((rean_t850_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_env_gen=rean_env_gen.rename({'longitude':'lon'});rean_env_gen=rean_env_gen.rename({'latitude':'lat'})\n",
    "rean_cp_gen=rean_cp_gen.rename({'longitude':'lon'});rean_cp_gen=rean_cp_gen.rename({'latitude':'lat'})\n",
    "rean_t850_gen=rean_t850_gen.rename({'longitude':'lon'});rean_t850_gen=rean_t850_gen.rename({'latitude':'lat'})\n",
    "# rean_env_gen = rean_env_gen.sel(time=[bool(i) for i in rean_env_gen.time.dt.hour%24==0])\n",
    "# rean_cp_gen = rean_cp_gen.sel(time=[bool(i) for i in rean_cp_gen.time.dt.hour%24==0])\n",
    "\n",
    "ERA5RF_env_gen = xr.open_dataset(file_ERA5RF_env,decode_times=False).squeeze()\n",
    "GFS_env_gen = xr.open_dataset(file_GFS_env,decode_times=False).squeeze()\n",
    "ERA5RF_cp_gen = xr.open_dataset(file_ERA5RF_cp,decode_times=False).squeeze()\n",
    "GFS_cp_gen = xr.open_dataset(file_GFS_cp,decode_times=False).squeeze()\n",
    "ERA5RF_t850_gen = xr.open_dataset(file_ERA5RF_t850,decode_times=False).squeeze()\n",
    "GFS_t850_gen = xr.open_dataset(file_GFS_t850,decode_times=False).squeeze()\n",
    "\n",
    "\n",
    "GFS_init_time = pd.Timestamp('1800-01-01')\n",
    "ERA5RF_init_time = pd.Timestamp('1900-01-01')\n",
    "GFS_env_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_env_gen.time.values]\n",
    "GFS_cp_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_cp_gen.time.values]\n",
    "GFS_t850_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_t850_gen.time.values]\n",
    "ERA5RF_env_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_env_gen.time.values]\n",
    "ERA5RF_cp_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_cp_gen.time.values]\n",
    "ERA5RF_t850_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_t850_gen.time.values]\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'lon':'longitude','lat':'latitude'}); GFS_cp_gen = GFS_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'lon':'longitude','lat':'latitude'}); ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "ERA5RF_t850_gen = ERA5RF_t850_gen.rename({'lon':'longitude','lat':'latitude'});GFS_t850_gen = GFS_t850_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.assign_coords(longitude=(((GFS_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "GFS_cp_gen = GFS_cp_gen.assign_coords(longitude=(((GFS_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "GFS_t850_gen = GFS_t850_gen.assign_coords(longitude=(((GFS_t850_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.assign_coords(longitude=(((ERA5RF_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.assign_coords(longitude=(((ERA5RF_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_t850_gen = ERA5RF_t850_gen.assign_coords(longitude=(((ERA5RF_t850_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "\n",
    "# GFS_env_gen = GFS_env_gen.sel(lead=GFS_env_gen.lead.values[[bool(i) for i in GFS_env_gen.lead%24==0]])\n",
    "# GFS_cp_gen = GFS_cp_gen.sel(lead=GFS_cp_gen.lead.values[[bool(i) for i in GFS_cp_gen.lead%24==0]])\n",
    "# ERA5RF_env_gen = ERA5RF_env_gen.sel(lead=ERA5RF_env_gen.lead.values[[bool(i) for i in ERA5RF_env_gen.lead%24==0]])\n",
    "# ERA5RF_cp_gen = ERA5RF_cp_gen.sel(lead=ERA5RF_cp_gen.lead.values[[bool(i) for i in ERA5RF_cp_gen.lead%24==0]])\n",
    "\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "GFS_cp_gen = GFS_cp_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "GFS_t850_gen = GFS_t850_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_t850_gen = ERA5RF_t850_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "# (44,36,352,360), #Spain\n",
    "# (54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "# (42,34,28,36), #Turkey\n",
    "# (68,60,22,30), #Finland\n",
    "# (66,58,6,14) #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_dayz = [3,5]\n",
    "for lead_day in lead_dayz:\n",
    "    for i,model in enumerate(modelz):\n",
    "        fcst_env_gen = fcstz_env[i]\n",
    "        fcst_cp_gen = fcstz_cp[i]\n",
    "        for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "            list_df = []\n",
    "            for season in seasonz:\n",
    "                for event in eventz:\n",
    "                    datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                    monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                    datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "    #                 for rank in rankz:\n",
    "\n",
    "\n",
    "    #                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "    #                                                                                                                     event,\n",
    "    #                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "    #                                                                                                                     season,model),\n",
    "    #                                      index_col=0)\n",
    "    #                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                    lon_0_RWP = lon_0 - 8\n",
    "                    lon_1_RWP = lon_1 + 6\n",
    "                    lat_0_RWP = lat_0 + 6\n",
    "                    lat_1_RWP = lat_1 - 8\n",
    "                    if lon_0_RWP>180:\n",
    "                        lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                    all_meanz_env = []\n",
    "                    all_meanz_cp = []\n",
    "                    all_meanz_t850 = []\n",
    "                    for date_event in datez_event:\n",
    "                        begin_date_event,end_date_event = date_event\n",
    "                        rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "\n",
    "                        rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "                        rean_t850_sub = rean_t850_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "                        all_meanz_env.append(rean_env_sub.mean(dim='time'))\n",
    "                        all_meanz_cp.append(rean_cp_sub.mean(dim='time'))\n",
    "                        all_meanz_t850.append(rean_t850_sub.mean(dim='time'))\n",
    "                    rean_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "                    rean_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "                    rean_t850_sub_all = xr.concat(all_meanz_t850,dim='time')\n",
    "\n",
    "                    rean_env_median = rean_env_sub_all.median(dim=['lat','lon']).v\n",
    "                    rean_cp_median = rean_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "                    .where((rean_cp_sub_all.v.count(dim=['lat','lon'])/len(rean_cp_sub_all.lat)**2)>=.2)\n",
    "                    rean_t850_median = rean_t850_sub_all.median(dim=['lat','lon']).t\n",
    "\n",
    "                    rean_env_standardized = (rean_env_median - rean_env_median.mean())/rean_env_median.std()\n",
    "                    rean_cp_standardized = (rean_cp_median - rean_cp_median.mean())/rean_cp_median.std()\n",
    "                    rean_t850_standardized = (rean_t850_median - rean_t850_median.mean())/rean_t850_median.std()\n",
    "\n",
    "                    df_norm = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed','T850'])\n",
    "                    df_norm.loc[:,'envelope'] = rean_env_standardized\n",
    "                    df_norm.loc[:,'phasespeed'] = rean_cp_standardized\n",
    "                    df_norm.loc[:,'T850'] = rean_t850_standardized\n",
    "                    df_norm.loc['mean'] = df_norm.mean().values\n",
    "\n",
    "                    df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed','T850'])\n",
    "                    df_av.loc[:,'envelope'] = rean_env_median\n",
    "                    df_av.loc[:,'phasespeed'] = rean_cp_median\n",
    "                    df_av.loc[:,'T850'] = rean_t850_median\n",
    "                    good_forecasts = pd.read_csv(path_gen+'/GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                    bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                    df_norm_good = df_norm[df_norm.index.isin(good_forecasts)]\n",
    "                    df_norm_bad = df_norm[df_norm.index.isin(bad_forecasts)]\n",
    "                    df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                    df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "\n",
    "                    df_av_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_av_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    #                 if len(all_meanz_cp)==0:\n",
    "    #                     df.loc[rank]=[np.nan,np.nan]\n",
    "    #                     df.loc[:,'envelope']=np.nan\n",
    "    #                     df.loc[:,'phasespeed']=np.nan\n",
    "    #                 else:\n",
    "    #                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "    #                 list_df.append(df)\n",
    "    #             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "    #                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "    #                 for df in list_df:\n",
    "    #                     foo.write(df.to_string())\n",
    "    #                     foo.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_dataset'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "fcstz_t850 = [GFS_t850_gen,ERA5RF_t850_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_dayz = [3,5]\n",
    "\n",
    "for i,model in enumerate(modelz):\n",
    "    for lead_day in lead_dayz:\n",
    "        fcst_env_gen = fcstz_env[i]\n",
    "        fcst_cp_gen = fcstz_cp[i]\n",
    "        fcst_t850_gen = fcstz_t850[i]\n",
    "        for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "            list_df = []\n",
    "            for season in seasonz:\n",
    "                for event in eventz:\n",
    "                    datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                    monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                    datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "    #                 for rank in rankz:\n",
    "\n",
    "\n",
    "    #                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "    #                                                                                                                     event,\n",
    "    #                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "    #                                                                                                                     season,model),\n",
    "    #                                      index_col=0)\n",
    "    #                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                    lon_0_RWP = lon_0 - 8\n",
    "                    lon_1_RWP = lon_1 + 6\n",
    "                    lat_0_RWP = lat_0 + 6\n",
    "                    lat_1_RWP = lat_1 - 8\n",
    "                    if lon_0_RWP>180:\n",
    "                        lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                    all_meanz_env = []\n",
    "                    all_meanz_cp = []\n",
    "                    all_meanz_t850 = []\n",
    "                    df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed','T850'])\n",
    "                    for date_event in datez_event:\n",
    "                        begin_date_event,end_date_event = date_event\n",
    "                        begin_date_fcst = begin_date_event - pd.Timedelta(lead_day*24,'hours')\n",
    "                        end_date_fcst = begin_date_fcst + pd.Timedelta(9*24,'hours')\n",
    "\n",
    "                        if end_date_event>end_date_fcst:\n",
    "                            end_date_event = end_date_fcst\n",
    "                        end_lead_hours_object = ((end_date_event - begin_date_fcst) + pd.Timedelta(18,'h'))\n",
    "                        end_lead_hours = end_lead_hours_object.days*24 + end_lead_hours_object.seconds//3600 \n",
    "                        try:\n",
    "                            rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                            if model == 'ERA5RF':\n",
    "                                rean_env_sub = rean_env_sub.sel(time=pd.date_range(begin_date_event,end_date_event+pd.Timedelta(18,'h'),freq='12H'))\n",
    "                            fcst_env_sub = fcst_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                            diff_fcst_env = fcst_env_sub - rean_env_sub.v.values\n",
    "                            diff_env_median = diff_fcst_env.median(dim=['lat','lon']).v\n",
    "                            \n",
    "                            rean_t850_sub = rean_t850_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                            fcst_t850_sub = fcst_t850_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                            if model == 'ERA5RF':\n",
    "                                rean_t850_sub = rean_t850_sub.sel(time=pd.date_range(begin_date_event,end_date_event+pd.Timedelta(18,'h'),freq='12H'))\n",
    "                            diff_fcst_t850 = fcst_t850_sub - rean_t850_sub.t.values\n",
    "                            diff_t850_median = diff_fcst_t850.median(dim=['lat','lon']).t\n",
    "                            \n",
    "                            if model == 'GFS':\n",
    "\n",
    "                                rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                            time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                                fcst_cp_sub = fcst_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                            time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                                diff_fcst_cp = fcst_cp_sub - rean_cp_sub.v.values\n",
    "                                diff_cp_median = diff_fcst_cp.median(dim=['lat','lon']).v\\\n",
    "                                .where((diff_fcst_cp.v.count(dim=['lat','lon'])/len(diff_fcst_cp.lat)**2)>=.2)\n",
    "                                \n",
    "                                df_av.loc[begin_date_event,'phasespeed'] = float(diff_cp_median.mean())\n",
    "\n",
    "                            df_av.loc[begin_date_event,'envelope'] = float(diff_env_median.mean())\n",
    "                            df_av.loc[begin_date_event,'T850'] = float(diff_t850_median.mean())\n",
    "\n",
    "                        except KeyError:\n",
    "                            df_av.loc[begin_date_event,'envelope'] = np.nan\n",
    "                            df_av.loc[begin_date_event,'T850'] = np.nan\n",
    "                            if model == 'GFS':\n",
    "                                df_av.loc[begin_date_event,'phasespeed'] = np.nan\n",
    "                    df_norm = (df_av - df_av.mean())/df_av.std()\n",
    "\n",
    "    #                     all_meanz_env.append(diff_fcst_env.mean(dim='lead'))\n",
    "    #                     all_meanz_cp.append(diff_fcst_cp.mean(dim='lead'))\n",
    "    #                 diff_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "    #                 diff_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "    #                 diff_env_median = diff_env_sub_all.median(dim=['lat','lon']).v\n",
    "    #                 diff_cp_median = diff_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "    #                 .where((diff_cp_sub_all.v.count(dim=['lat','lon'])/len(diff_cp_sub_all.lat)**2)>=.2)\n",
    "\n",
    "\n",
    "\n",
    "    #                 df.loc[:,'envelope'] = diff_env_standardized\n",
    "    #                 df.loc[:,'phasespeed'] = diff_cp_standardized\n",
    "    #                 df.loc['mean'] = df.mean().values\n",
    "                    good_forecasts = pd.read_csv(path_gen+'/GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                    bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                    df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                    df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "                    df_norm_good = df_norm[df_av.index.isin(good_forecasts)]\n",
    "                    df_norm_bad = df_norm[df_av.index.isin(bad_forecasts)]\n",
    "                    df_av_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_av_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "    #                 if len(all_meanz_cp)==0:\n",
    "    #                     df.loc[rank]=[np.nan,np.nan]\n",
    "    #                     df.loc[:,'envelope']=np.nan\n",
    "    #                     df.loc[:,'phasespeed']=np.nan\n",
    "    #                 else:\n",
    "    #                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "    #                 list_df.append(df)\n",
    "    #             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "    #                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "    #                 for df in list_df:\n",
    "    #                     foo.write(df.to_string())\n",
    "    #                     foo.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
