{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "peripheral-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from my_tools import file_dic, plot_dic\n",
    "from cmap import ncl_colormap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "%matplotlib qt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verbal-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path for \n",
    "path_gen = '/media/onno/Algemeen/Thesis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promising-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load RWP property files\n",
    "file_rean_env = path_gen + file_dic['envelope']['ERA5']\n",
    "file_rean_cp = path_gen + file_dic['phasespeed']['ERA5']\n",
    "file_GFS_env = path_gen + file_dic['envelope']['GFS']\n",
    "file_GFS_cp = path_gen + file_dic['phasespeed']['GFS']\n",
    "file_ERA5RF_env = path_gen + file_dic['envelope']['ERA5RF']\n",
    "file_ERA5RF_cp = path_gen + file_dic['phasespeed']['ERA5RF']\n",
    "\n",
    "rean_env_gen = xr.open_dataset(file_rean_env).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_cp_gen = xr.open_dataset(file_rean_cp).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_env_gen =  rean_env_gen.assign_coords(longitude=(((rean_env_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_cp_gen =  rean_cp_gen.assign_coords(longitude=(((rean_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "\n",
    "rean_env_gen=rean_env_gen.rename({'longitude':'lon'});rean_env_gen=rean_env_gen.rename({'latitude':'lat'})\n",
    "rean_cp_gen=rean_cp_gen.rename({'longitude':'lon'});rean_cp_gen=rean_cp_gen.rename({'latitude':'lat'})\n",
    "# rean_env_gen = rean_env_gen.sel(time=[bool(i) for i in rean_env_gen.time.dt.hour%24==0])\n",
    "# rean_cp_gen = rean_cp_gen.sel(time=[bool(i) for i in rean_cp_gen.time.dt.hour%24==0])\n",
    "\n",
    "ERA5RF_env_gen = xr.open_dataset(file_ERA5RF_env,decode_times=False).squeeze()\n",
    "GFS_env_gen = xr.open_dataset(file_GFS_env,decode_times=False).squeeze()\n",
    "ERA5RF_cp_gen = xr.open_dataset(file_ERA5RF_cp,decode_times=False).squeeze()\n",
    "GFS_cp_gen = xr.open_dataset(file_GFS_cp,decode_times=False).squeeze()\n",
    "\n",
    "GFS_init_time = pd.Timestamp('1800-01-01')\n",
    "ERA5RF_init_time = pd.Timestamp('1900-01-01')\n",
    "GFS_env_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_env_gen.time.values]\n",
    "GFS_cp_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_cp_gen.time.values]\n",
    "ERA5RF_env_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_env_gen.time.values]\n",
    "ERA5RF_cp_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_cp_gen.time.values]\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'lon':'longitude','lat':'latitude'}); GFS_cp_gen = GFS_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'lon':'longitude','lat':'latitude'}); ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "GFS_env_gen = GFS_env_gen.assign_coords(longitude=(((GFS_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "GFS_cp_gen = GFS_cp_gen.assign_coords(longitude=(((GFS_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.assign_coords(longitude=(((ERA5RF_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.assign_coords(longitude=(((ERA5RF_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "# GFS_env_gen = GFS_env_gen.sel(lead=GFS_env_gen.lead.values[[bool(i) for i in GFS_env_gen.lead%24==0]])\n",
    "# GFS_cp_gen = GFS_cp_gen.sel(lead=GFS_cp_gen.lead.values[[bool(i) for i in GFS_cp_gen.lead%24==0]])\n",
    "# ERA5RF_env_gen = ERA5RF_env_gen.sel(lead=ERA5RF_env_gen.lead.values[[bool(i) for i in ERA5RF_env_gen.lead%24==0]])\n",
    "# ERA5RF_cp_gen = ERA5RF_cp_gen.sel(lead=ERA5RF_cp_gen.lead.values[[bool(i) for i in ERA5RF_cp_gen.lead%24==0]])\n",
    "\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "GFS_cp_gen = GFS_cp_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'latitude':'lat','longitude':'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_data'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = ['MAM','JJA','SON','DJF']\n",
    "lead_day = 5\n",
    "for i,model in enumerate(modelz):\n",
    "    fcst_env_gen = fcstz_env[i]\n",
    "    fcst_cp_gen = fcstz_cp[i]\n",
    "    for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "        list_df = []\n",
    "        for season in seasonz:\n",
    "            for event in eventz:\n",
    "                datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                for rank in rankz:\n",
    "\n",
    "\n",
    "                    df = pd.read_csv(path_gen+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "                                                                                                                    event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model),\n",
    "                                     index_col=0)\n",
    "                    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                    lon_0_RWP = lon_0 - 8\n",
    "                    lon_1_RWP = lon_1 + 6\n",
    "                    lat_0_RWP = lat_0 + 6\n",
    "                    lat_1_RWP = lat_1 - 8\n",
    "                    if lon_0_RWP>180:\n",
    "                        lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                    all_meanz_env = []\n",
    "                    all_meanz_cp = []\n",
    "                    for date in df.index:\n",
    "                        index = int(np.squeeze(np.where(datez_event[:,0]==date)))\n",
    "                        date_event = datez_event[index]\n",
    "                        begin_date_event,end_date_event = date_event\n",
    "                        begin_date_fcst = begin_date_event - pd.Timedelta(,'days')\n",
    "                        end_date_fcst = begin_date_fcst + pd.Timedelta(9,'days')\n",
    "\n",
    "                        if end_date_event>end_date_fcst:\n",
    "                            end_date_event = end_date_fcst\n",
    "                        end_lead_day = (end_date_event - begin_date_fcst).days\n",
    "                        rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event))\n",
    "                        fcst_env_sub = fcst_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day,end_lead_day))\n",
    "                        diff_fcst_env = fcst_env_sub - rean_env_sub.v.values\n",
    "\n",
    "                        rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event))\n",
    "                        fcst_cp_sub = fcst_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day,end_lead_day))\n",
    "                        diff_fcst_cp = fcst_cp_sub - rean_cp_sub.v.values\n",
    "                        all_meanz_env.append(diff_fcst_env.mean(dim='lead'))\n",
    "                        all_meanz_cp.append(diff_fcst_cp.mean(dim='lead'))\n",
    "                    if len(all_meanz_cp)>0:\n",
    "                        diff_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "                        diff_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "                        diff_env_mean = my_tools.weighted_average_area_3D(diff_env_sub_all,variable='envelope')\n",
    "                        diff_cp_median = diff_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "                        .where((diff_cp_sub_all.v.count(dim=['lat','lon'])/len(diff_cp_sub_all.lat)**2)>=.2)\n",
    "                        \n",
    "                        df.loc[:,'envelope'] = diff_env_mean\n",
    "                        df.loc[:,'phasespeed'] = diff_cp_median\n",
    "                        df.loc['mean'] = df.mean().values\n",
    "                    df.to_csv(path+'fcst_RWP_properties/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model))\n",
    "                    if len(all_meanz_cp)==0:\n",
    "                        df.loc[rank]=[np.nan,np.nan]\n",
    "                        df.loc[:,'envelope']=np.nan\n",
    "                        df.loc[:,'phasespeed']=np.nan\n",
    "                    else:\n",
    "                        df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "                    list_df.append(df)\n",
    "            with open(path+'fcst_RWP_properties/seasonal/forecasts_errors{}_lon_{}_{}_lat_{}_{}_RWP_total_{}_lead_day_{}.txt'.format(dataset_type,\n",
    "                                                                                                                         lon_0,lon_1,lat_0,lat_1,model,lead_day),'w') as foo:\n",
    "                for df in list_df:\n",
    "                    foo.write(df.to_string())\n",
    "                    foo.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_dataset'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_day = 3\n",
    "for i,model in enumerate(modelz):\n",
    "    fcst_env_gen = fcstz_env[i]\n",
    "    fcst_cp_gen = fcstz_cp[i]\n",
    "    for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "        list_df = []\n",
    "        for season in seasonz:\n",
    "            for event in eventz:\n",
    "                datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "#                 for rank in rankz:\n",
    "\n",
    "\n",
    "#                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "#                                                                                                                     event,\n",
    "#                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "#                                                                                                                     season,model),\n",
    "#                                      index_col=0)\n",
    "#                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                lon_0_RWP = lon_0 - 8\n",
    "                lon_1_RWP = lon_1 + 6\n",
    "                lat_0_RWP = lat_0 + 6\n",
    "                lat_1_RWP = lat_1 - 8\n",
    "                if lon_0_RWP>180:\n",
    "                    lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                all_meanz_env = []\n",
    "                all_meanz_cp = []\n",
    "                for date_event in datez_event:\n",
    "                    begin_date_event,end_date_event = date_event\n",
    "                    rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "\n",
    "                    rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "                    all_meanz_env.append(rean_env_sub.mean(dim='time'))\n",
    "                    all_meanz_cp.append(rean_cp_sub.mean(dim='time'))\n",
    "                rean_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "                rean_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "                rean_env_median = rean_env_sub_all.median(dim=['lat','lon']).v\n",
    "                rean_cp_median = rean_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "                .where((rean_cp_sub_all.v.count(dim=['lat','lon'])/len(rean_cp_sub_all.lat)**2)>=.2)\n",
    "                \n",
    "                rean_env_standardized = (rean_env_median - rean_env_median.mean())/rean_env_median.std()\n",
    "                rean_cp_standardized = (rean_cp_median - rean_cp_median.mean())/rean_cp_median.std()\n",
    "\n",
    "                df_norm = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed'])\n",
    "                df_norm.loc[:,'envelope'] = rean_env_standardized\n",
    "                df_norm.loc[:,'phasespeed'] = rean_cp_standardized\n",
    "                df_norm.loc['mean'] = df.mean().values\n",
    "                \n",
    "                df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed'])\n",
    "                df_av.loc[:,'envelope'] = rean_env_median\n",
    "                df_av.loc[:,'phasespeed'] = rean_cp_median\n",
    "                good_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model,lead_day),\n",
    "                                     index_col=0).index\n",
    "                good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model,lead_day),\n",
    "                                     index_col=0).index\n",
    "                bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                df_norm_good = df_norm[df_norm.index.isin(good_forecasts)]\n",
    "                df_norm_bad = df_norm[df_norm.index.isin(bad_forecasts)]\n",
    "                df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "                \n",
    "                df_av_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_av_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "#                 if len(all_meanz_cp)==0:\n",
    "#                     df.loc[rank]=[np.nan,np.nan]\n",
    "#                     df.loc[:,'envelope']=np.nan\n",
    "#                     df.loc[:,'phasespeed']=np.nan\n",
    "#                 else:\n",
    "#                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "#                 list_df.append(df)\n",
    "#             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "#                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "#                 for df in list_df:\n",
    "#                     foo.write(df.to_string())\n",
    "#                     foo.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "(44,36,352,360), #Spain\n",
    "(54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "(42,34,28,36), #Turkey\n",
    "(68,60,22,30), #Finland\n",
    "(66,58,6,14), #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_dataset'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_day = 3\n",
    "for i,model in enumerate(modelz):\n",
    "    fcst_env_gen = fcstz_env[i]\n",
    "    fcst_cp_gen = fcstz_cp[i]\n",
    "    for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "        list_df = []\n",
    "        for season in seasonz:\n",
    "            for event in eventz:\n",
    "                datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "#                 for rank in rankz:\n",
    "\n",
    "\n",
    "#                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "#                                                                                                                     event,\n",
    "#                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "#                                                                                                                     season,model),\n",
    "#                                      index_col=0)\n",
    "#                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                lon_0_RWP = lon_0 - 8\n",
    "                lon_1_RWP = lon_1 + 6\n",
    "                lat_0_RWP = lat_0 + 6\n",
    "                lat_1_RWP = lat_1 - 8\n",
    "                if lon_0_RWP>180:\n",
    "                    lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                all_meanz_env = []\n",
    "                all_meanz_cp = []\n",
    "                df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed'])\n",
    "                for date_event in datez_event:\n",
    "                    begin_date_event,end_date_event = date_event\n",
    "                    begin_date_fcst = begin_date_event - pd.Timedelta(lead_day*24,'hours')\n",
    "                    end_date_fcst = begin_date_fcst + pd.Timedelta(9*24,'hours')\n",
    "\n",
    "                    if end_date_event>end_date_fcst:\n",
    "                        end_date_event = end_date_fcst\n",
    "                    end_lead_hours_object = ((end_date_event - begin_date_fcst) + pd.Timedelta(18,'h'))\n",
    "                    end_lead_hours = end_lead_hours_object.days*24 + end_lead_hours_object.seconds//3600 \n",
    "                    try:\n",
    "                        rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                        fcst_env_sub = fcst_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                        diff_fcst_env = fcst_env_sub - rean_env_sub.v.values\n",
    "\n",
    "                        rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                        fcst_cp_sub = fcst_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                        diff_fcst_cp = fcst_cp_sub - rean_cp_sub.v.values\n",
    "\n",
    "                        diff_env_median = diff_fcst_env.median(dim=['lat','lon']).v\n",
    "                        diff_cp_median = diff_fcst_cp.median(dim=['lat','lon']).v\\\n",
    "                        .where((diff_fcst_cp.v.count(dim=['lat','lon'])/len(diff_fcst_cp.lat)**2)>=.2)\n",
    "\n",
    "                        df_av.loc[begin_date_event,'envelope'] = float(diff_env_median.mean())\n",
    "                        df_av.loc[begin_date_event,'phasespeed'] = float(diff_cp_median.mean())\n",
    "                    except KeyError:\n",
    "                        df.loc[begin_date_event,'envelope'] = np.nan\n",
    "                        df.loc[begin_date_event,'phasespeed'] = np.nan\n",
    "                df_norm = (df_av - df_av.mean())/df_av.std()\n",
    "    \n",
    "#                     all_meanz_env.append(diff_fcst_env.mean(dim='lead'))\n",
    "#                     all_meanz_cp.append(diff_fcst_cp.mean(dim='lead'))\n",
    "#                 diff_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "#                 diff_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "#                 diff_env_median = diff_env_sub_all.median(dim=['lat','lon']).v\n",
    "#                 diff_cp_median = diff_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "#                 .where((diff_cp_sub_all.v.count(dim=['lat','lon'])/len(diff_cp_sub_all.lat)**2)>=.2)\n",
    "\n",
    "                \n",
    "\n",
    "#                 df.loc[:,'envelope'] = diff_env_standardized\n",
    "#                 df.loc[:,'phasespeed'] = diff_cp_standardized\n",
    "#                 df.loc['mean'] = df.mean().values\n",
    "                good_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model,lead_day),\n",
    "                                     index_col=0).index\n",
    "                good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                  lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                    season,model,lead_day),\n",
    "                                     index_col=0).index\n",
    "                bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "                df_norm_good = df_norm[df_av.index.isin(good_forecasts)]\n",
    "                df_norm_bad = df_norm[df_av.index.isin(bad_forecasts)]                \n",
    "                df_av_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_av_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_good.to_csv(path_gen+'fcst_RWP_properties/good_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "                df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/bad_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                        lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                             season,model,lead_day))\n",
    "#                 if len(all_meanz_cp)==0:\n",
    "#                     df.loc[rank]=[np.nan,np.nan]\n",
    "#                     df.loc[:,'envelope']=np.nan\n",
    "#                     df.loc[:,'phasespeed']=np.nan\n",
    "#                 else:\n",
    "#                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "#                 list_df.append(df)\n",
    "#             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "#                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "#                 for df in list_df:\n",
    "#                     foo.write(df.to_string())\n",
    "#                     foo.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-medication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
