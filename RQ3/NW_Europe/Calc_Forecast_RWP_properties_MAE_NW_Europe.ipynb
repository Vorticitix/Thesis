{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aerial-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/onno/Thesis/Scripts')\n",
    "import my_tools\n",
    "from my_tools import file_dic, plot_dic\n",
    "from cmap import ncl_colormap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "%matplotlib qt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expired-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path for \n",
    "path_gen = '/media/onno/Algemeen/Thesis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "labeled-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load RWP property files\n",
    "file_rean_env = path_gen + file_dic['envelope']['ERA5']\n",
    "file_rean_cp = path_gen + file_dic['phasespeed']['ERA5']\n",
    "file_rean_t850 = path_gen + file_dic['T850']['ERA5']\n",
    "file_GFS_env = path_gen + file_dic['envelope']['GFS']\n",
    "file_GFS_cp = path_gen + file_dic['phasespeed']['GFS']\n",
    "file_GFS_t850 = path_gen + file_dic['T850']['GFS']\n",
    "file_ERA5RF_env = path_gen + file_dic['envelope']['ERA5RF']\n",
    "file_ERA5RF_cp = path_gen + file_dic['phasespeed']['ERA5RF']\n",
    "file_ERA5RF_t850 = path_gen + file_dic['T850']['ERA5RF']\n",
    "\n",
    "\n",
    "rean_env_gen = xr.open_dataset(file_rean_env).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_cp_gen = xr.open_dataset(file_rean_cp).sel(latitude=slice(90,0)).squeeze()\n",
    "rean_t850_gen = xr.open_dataset(file_rean_t850).sel(latitude=slice(90,0)).squeeze()\n",
    "\n",
    "rean_env_gen =  rean_env_gen.assign_coords(longitude=(((rean_env_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_cp_gen =  rean_cp_gen.assign_coords(longitude=(((rean_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_t850_gen = rean_t850_gen.assign_coords(longitude=(((rean_t850_gen.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "rean_env_gen=rean_env_gen.rename({'longitude':'lon'});rean_env_gen=rean_env_gen.rename({'latitude':'lat'})\n",
    "rean_cp_gen=rean_cp_gen.rename({'longitude':'lon'});rean_cp_gen=rean_cp_gen.rename({'latitude':'lat'})\n",
    "rean_t850_gen=rean_t850_gen.rename({'longitude':'lon'});rean_t850_gen=rean_t850_gen.rename({'latitude':'lat'})\n",
    "# rean_env_gen = rean_env_gen.sel(time=[bool(i) for i in rean_env_gen.time.dt.hour%24==0])\n",
    "# rean_cp_gen = rean_cp_gen.sel(time=[bool(i) for i in rean_cp_gen.time.dt.hour%24==0])\n",
    "\n",
    "ERA5RF_env_gen = xr.open_dataset(file_ERA5RF_env,decode_times=False).squeeze()\n",
    "GFS_env_gen = xr.open_dataset(file_GFS_env,decode_times=False).squeeze()\n",
    "ERA5RF_cp_gen = xr.open_dataset(file_ERA5RF_cp,decode_times=False).squeeze()\n",
    "GFS_cp_gen = xr.open_dataset(file_GFS_cp,decode_times=False).squeeze()\n",
    "ERA5RF_t850_gen = xr.open_dataset(file_ERA5RF_t850,decode_times=False).squeeze()\n",
    "GFS_t850_gen = xr.open_dataset(file_GFS_t850,decode_times=False).squeeze()\n",
    "\n",
    "\n",
    "GFS_init_time = pd.Timestamp('1800-01-01')\n",
    "ERA5RF_init_time = pd.Timestamp('1900-01-01')\n",
    "GFS_env_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_env_gen.time.values]\n",
    "GFS_cp_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_cp_gen.time.values]\n",
    "GFS_t850_gen['time']=[pd.Timedelta(i,'hours')+GFS_init_time for i in GFS_t850_gen.time.values]\n",
    "ERA5RF_env_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_env_gen.time.values]\n",
    "ERA5RF_cp_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_cp_gen.time.values]\n",
    "ERA5RF_t850_gen['time']=[pd.Timedelta(i,'hours')+ERA5RF_init_time for i in ERA5RF_t850_gen.time.values]\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'lon':'longitude','lat':'latitude'}); GFS_cp_gen = GFS_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'lon':'longitude','lat':'latitude'}); ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "ERA5RF_t850_gen = ERA5RF_t850_gen.rename({'lon':'longitude','lat':'latitude'});GFS_t850_gen = GFS_t850_gen.rename({'lon':'longitude','lat':'latitude'})\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.assign_coords(longitude=(((GFS_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "GFS_cp_gen = GFS_cp_gen.assign_coords(longitude=(((GFS_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "GFS_t850_gen = GFS_t850_gen.assign_coords(longitude=(((GFS_t850_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.assign_coords(longitude=(((ERA5RF_env_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.assign_coords(longitude=(((ERA5RF_cp_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "ERA5RF_t850_gen = ERA5RF_t850_gen.assign_coords(longitude=(((ERA5RF_t850_gen.longitude + 180) % 360) - 180)).sortby('longitude').sel(latitude=slice(90,0))\n",
    "\n",
    "# GFS_env_gen = GFS_env_gen.sel(lead=GFS_env_gen.lead.values[[bool(i) for i in GFS_env_gen.lead%24==0]])\n",
    "# GFS_cp_gen = GFS_cp_gen.sel(lead=GFS_cp_gen.lead.values[[bool(i) for i in GFS_cp_gen.lead%24==0]])\n",
    "# ERA5RF_env_gen = ERA5RF_env_gen.sel(lead=ERA5RF_env_gen.lead.values[[bool(i) for i in ERA5RF_env_gen.lead%24==0]])\n",
    "# ERA5RF_cp_gen = ERA5RF_cp_gen.sel(lead=ERA5RF_cp_gen.lead.values[[bool(i) for i in ERA5RF_cp_gen.lead%24==0]])\n",
    "\n",
    "\n",
    "GFS_env_gen = GFS_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "GFS_cp_gen = GFS_cp_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "GFS_t850_gen = GFS_t850_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_env_gen = ERA5RF_env_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_cp_gen = ERA5RF_cp_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "ERA5RF_t850_gen = ERA5RF_t850_gen.rename({'latitude':'lat','longitude':'lon'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "genetic-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "# (44,36,352,360), #Spain\n",
    "# (54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "# (42,34,28,36), #Turkey\n",
    "# (68,60,22,30), #Finland\n",
    "# (66,58,6,14) #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_dayz = [3,5]\n",
    "for lead_day in lead_dayz:\n",
    "    for i,model in enumerate(modelz):\n",
    "        fcst_env_gen = fcstz_env[i]\n",
    "        fcst_cp_gen = fcstz_cp[i]\n",
    "        for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "            list_df = []\n",
    "            for season in seasonz:\n",
    "                for event in eventz:\n",
    "                    datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                    monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                    datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "    #                 for rank in rankz:\n",
    "\n",
    "\n",
    "    #                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "    #                                                                                                                     event,\n",
    "    #                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "    #                                                                                                                     season,model),\n",
    "    #                                      index_col=0)\n",
    "    #                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                    lon_0_RWP = lon_0 - 8\n",
    "                    lon_1_RWP = lon_1 + 6\n",
    "                    lat_0_RWP = lat_0 + 6\n",
    "                    lat_1_RWP = lat_1 - 8\n",
    "                    if lon_0_RWP>180:\n",
    "                        lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                    all_meanz_env = []\n",
    "                    all_meanz_cp = []\n",
    "                    all_meanz_t850 = []\n",
    "                    for date_event in datez_event:\n",
    "                        begin_date_event,end_date_event = date_event\n",
    "                        rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "\n",
    "                        rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "                        rean_t850_sub = rean_t850_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                    time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'hours')))\n",
    "                        all_meanz_env.append(rean_env_sub.mean(dim='time'))\n",
    "                        all_meanz_cp.append(rean_cp_sub.mean(dim='time'))\n",
    "                        all_meanz_t850.append(rean_t850_sub.mean(dim='time'))\n",
    "                    rean_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "                    rean_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "                    rean_t850_sub_all = xr.concat(all_meanz_t850,dim='time')\n",
    "\n",
    "                    rean_env_median = rean_env_sub_all.median(dim=['lat','lon']).v\n",
    "                    rean_cp_median = rean_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "                    .where((rean_cp_sub_all.v.count(dim=['lat','lon'])/len(rean_cp_sub_all.lat)**2)>=.2)\n",
    "                    rean_t850_median = rean_t850_sub_all.median(dim=['lat','lon']).t\n",
    "\n",
    "                    rean_env_standardized = (rean_env_median - rean_env_median.mean())/rean_env_median.std()\n",
    "                    rean_cp_standardized = (rean_cp_median - rean_cp_median.mean())/rean_cp_median.std()\n",
    "                    rean_t850_standardized = (rean_t850_median - rean_t850_median.mean())/rean_t850_median.std()\n",
    "\n",
    "                    df_norm = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed','T850'])\n",
    "                    df_norm.loc[:,'envelope'] = rean_env_standardized\n",
    "                    df_norm.loc[:,'phasespeed'] = rean_cp_standardized\n",
    "                    df_norm.loc[:,'T850'] = rean_t850_standardized\n",
    "                    df_norm.loc['mean'] = df_norm.mean().values\n",
    "\n",
    "                    df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed','T850'])\n",
    "                    df_av.loc[:,'envelope'] = rean_env_median\n",
    "                    df_av.loc[:,'phasespeed'] = rean_cp_median\n",
    "                    df_av.loc[:,'T850'] = rean_t850_median\n",
    "                    good_forecasts = pd.read_csv(path_gen+'/GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                    bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                    df_norm_good = df_norm[df_norm.index.isin(good_forecasts)]\n",
    "                    df_norm_bad = df_norm[df_norm.index.isin(bad_forecasts)]\n",
    "                    df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                    df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "\n",
    "                    df_av_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_av_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_RWP_properties_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_RWP_properties_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    #                 if len(all_meanz_cp)==0:\n",
    "    #                     df.loc[rank]=[np.nan,np.nan]\n",
    "    #                     df.loc[:,'envelope']=np.nan\n",
    "    #                     df.loc[:,'phasespeed']=np.nan\n",
    "    #                 else:\n",
    "    #                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "    #                 list_df.append(df)\n",
    "    #             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "    #                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "    #                 for df in list_df:\n",
    "    #                     foo.write(df.to_string())\n",
    "    #                     foo.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "approved-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coordinatez = [\n",
    "(54,46,6,14),#Germany\n",
    "# (44,36,352,360), #Spain\n",
    "# (54,46,26,34), #Ukraine\n",
    "(58,50,352,360), #UK\n",
    "# (42,34,28,36), #Turkey\n",
    "# (68,60,22,30), #Finland\n",
    "# (66,58,6,14) #Norway/Sweden\n",
    "(60,52,46,54)] #Russia Samara/Kazan region\n",
    "dataset_type = '_split_dataset'\n",
    "eventz = ['persistent_hw','persistent_cw','short_hw','short_cw']\n",
    "rankz = ['good','bad']\n",
    "fcstz_env = [GFS_env_gen,ERA5RF_env_gen]\n",
    "fcstz_cp = [GFS_cp_gen,ERA5RF_cp_gen]\n",
    "fcstz_t850 = [GFS_t850_gen,ERA5RF_t850_gen]\n",
    "modelz = ['GFS','ERA5RF']\n",
    "seasonz = {'JJA':[6,7,8],\n",
    "          'DJF':[12,1,2]}\n",
    "lead_dayz = [3,5]\n",
    "\n",
    "for i,model in enumerate(modelz):\n",
    "    for lead_day in lead_dayz:\n",
    "        fcst_env_gen = fcstz_env[i]\n",
    "        fcst_cp_gen = fcstz_cp[i]\n",
    "        fcst_t850_gen = fcstz_t850[i]\n",
    "        for lat_0,lat_1,lon_0,lon_1 in coordinatez:\n",
    "            list_df = []\n",
    "            for season in seasonz:\n",
    "                for event in eventz:\n",
    "                    datez_event = np.load(path_gen+ 'GFS_T850/{}_lon_{}_{}_lat_{}_{}.npy'.format(event,lon_0,lon_1-2,lat_0-2,lat_1))\n",
    "                    monthz = [i.month for i in pd.to_datetime(datez_event[:,0])]\n",
    "                    datez_event = datez_event[np.isin(monthz,seasonz[season])]\n",
    "    #                 for rank in rankz:\n",
    "\n",
    "\n",
    "    #                     df = pd.read_csv(path+'GFS_T850/rank_forecast/seasonal/{}_forecasts{}_{}_lon_{}_{}_lat_{}_{}_{}_{}.txt'.format(rank,dataset_type,\n",
    "    #                                                                                                                     event,\n",
    "    #                                                                                                                   lon_0,lon_1,lat_0,lat_1,\n",
    "    #                                                                                                                     season,model),\n",
    "    #                                      index_col=0)\n",
    "    #                     df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                    lon_0_RWP = lon_0 - 8\n",
    "                    lon_1_RWP = lon_1 + 6\n",
    "                    lat_0_RWP = lat_0 + 6\n",
    "                    lat_1_RWP = lat_1 - 8\n",
    "                    if lon_0_RWP>180:\n",
    "                        lon_0_RWP = lon_0_RWP - 360;lon_1_RWP = lon_1_RWP - 360\n",
    "                    all_meanz_env = []\n",
    "                    all_meanz_cp = []\n",
    "                    all_meanz_t850 = []\n",
    "                    df_av = pd.DataFrame(index=datez_event[:,0],columns=['envelope','phasespeed','T850'])\n",
    "                    for date_event in datez_event:\n",
    "                        begin_date_event,end_date_event = date_event\n",
    "                        begin_date_fcst = begin_date_event - pd.Timedelta(lead_day*24,'hours')\n",
    "                        end_date_fcst = begin_date_fcst + pd.Timedelta(9*24,'hours')\n",
    "\n",
    "                        if end_date_event>end_date_fcst:\n",
    "                            end_date_event = end_date_fcst\n",
    "                        end_lead_hours_object = ((end_date_event - begin_date_fcst) + pd.Timedelta(18,'h'))\n",
    "                        end_lead_hours = end_lead_hours_object.days*24 + end_lead_hours_object.seconds//3600 \n",
    "                        try:\n",
    "                            rean_env_sub = rean_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                            if model == 'ERA5RF':\n",
    "                                rean_env_sub = rean_env_sub.sel(time=pd.date_range(begin_date_event,end_date_event+pd.Timedelta(18,'h'),freq='12H'))\n",
    "                            fcst_env_sub = fcst_env_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                            diff_fcst_env = fcst_env_sub - rean_env_sub.v.values\n",
    "                            diff_env_median = diff_fcst_env.median(dim=['lat','lon']).v\n",
    "                            \n",
    "                            rean_t850_sub = rean_t850_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                            fcst_t850_sub = fcst_t850_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                        time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                            if model == 'ERA5RF':\n",
    "                                rean_t850_sub = rean_t850_sub.sel(time=pd.date_range(begin_date_event,end_date_event+pd.Timedelta(18,'h'),freq='12H'))\n",
    "                            diff_fcst_t850 = fcst_t850_sub - rean_t850_sub.t.values\n",
    "                            diff_t850_median = diff_fcst_t850.median(dim=['lat','lon']).t\n",
    "                            \n",
    "                            if model == 'GFS':\n",
    "\n",
    "                                rean_cp_sub = rean_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                            time=slice(begin_date_event,end_date_event+pd.Timedelta(18,'h')))\n",
    "                                fcst_cp_sub = fcst_cp_gen.sel(lat=slice(lat_0_RWP,lat_1_RWP),lon=slice(lon_0_RWP,lon_1_RWP),\n",
    "                                                            time=begin_date_fcst,lead=slice(lead_day*24,end_lead_hours))\n",
    "                                diff_fcst_cp = fcst_cp_sub - rean_cp_sub.v.values\n",
    "                                diff_cp_median = diff_fcst_cp.median(dim=['lat','lon']).v\\\n",
    "                                .where((diff_fcst_cp.v.count(dim=['lat','lon'])/len(diff_fcst_cp.lat)**2)>=.2)\n",
    "                                \n",
    "                                df_av.loc[begin_date_event,'phasespeed'] = float(diff_cp_median.mean())\n",
    "\n",
    "                            df_av.loc[begin_date_event,'envelope'] = float(diff_env_median.mean())\n",
    "                            df_av.loc[begin_date_event,'T850'] = float(diff_t850_median.mean())\n",
    "\n",
    "                        except KeyError:\n",
    "                            df_av.loc[begin_date_event,'envelope'] = np.nan\n",
    "                            df_av.loc[begin_date_event,'T850'] = np.nan\n",
    "                            if model == 'GFS':\n",
    "                                df_av.loc[begin_date_event,'phasespeed'] = np.nan\n",
    "                    df_norm = (df_av - df_av.mean())/df_av.std()\n",
    "\n",
    "    #                     all_meanz_env.append(diff_fcst_env.mean(dim='lead'))\n",
    "    #                     all_meanz_cp.append(diff_fcst_cp.mean(dim='lead'))\n",
    "    #                 diff_env_sub_all = xr.concat(all_meanz_env,dim='time')\n",
    "    #                 diff_cp_sub_all = xr.concat(all_meanz_cp,dim='time')\n",
    "\n",
    "    #                 diff_env_median = diff_env_sub_all.median(dim=['lat','lon']).v\n",
    "    #                 diff_cp_median = diff_cp_sub_all.median(dim=['lat','lon']).v\\\n",
    "    #                 .where((diff_cp_sub_all.v.count(dim=['lat','lon'])/len(diff_cp_sub_all.lat)**2)>=.2)\n",
    "\n",
    "\n",
    "\n",
    "    #                 df.loc[:,'envelope'] = diff_env_standardized\n",
    "    #                 df.loc[:,'phasespeed'] = diff_cp_standardized\n",
    "    #                 df.loc['mean'] = df.mean().values\n",
    "                    good_forecasts = pd.read_csv(path_gen+'/GFS_T850/rank_forecast/good_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    good_forecasts = pd.to_datetime(good_forecasts)\n",
    "                    bad_forecasts = pd.read_csv(path_gen+'GFS_T850/rank_forecast/bad_forecasts_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                                      lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                        season,model,lead_day),\n",
    "                                         index_col=0).index\n",
    "                    bad_forecasts = pd.to_datetime(bad_forecasts)\n",
    "                    df_av_good = df_av[df_av.index.isin(good_forecasts)]\n",
    "                    df_av_bad = df_av[df_av.index.isin(bad_forecasts)]\n",
    "                    df_norm_good = df_norm[df_av.index.isin(good_forecasts)]\n",
    "                    df_norm_bad = df_norm[df_av.index.isin(bad_forecasts)]\n",
    "                    df_av_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_av_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_errors_AV_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_good.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/good_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "                    df_norm_bad.to_csv(path_gen+'fcst_RWP_properties/NW_Europe/bad_forecasts_errors_standardized_{}_lon_{}_{}_lat_{}_{}_{}_{}_lead_day_{}.txt'.format(event,\n",
    "                                                                                                            lon_0,lon_1,lat_0,lat_1,\n",
    "                                                                                                                 season,model,lead_day))\n",
    "    #                 if len(all_meanz_cp)==0:\n",
    "    #                     df.loc[rank]=[np.nan,np.nan]\n",
    "    #                     df.loc[:,'envelope']=np.nan\n",
    "    #                     df.loc[:,'phasespeed']=np.nan\n",
    "    #                 else:\n",
    "    #                     df.loc[rank] = [np.nan,np.nan,np.nan,np.nan]\n",
    "    #                 list_df.append(df)\n",
    "    #             with open(path+'fcst_RWP_properties/seasonal/forecasts_RWP_properties{}_lon_{}_{}_lat_{}_{}_RWP_total_{}.txt'.format(dataset_type,\n",
    "    #                                                                                                                          lon_0,lon_1,lat_0,lat_1,model),'w') as foo:\n",
    "    #                 for df in list_df:\n",
    "    #                     foo.write(df.to_string())\n",
    "    #                     foo.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-chase",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
